{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cd13875"
      },
      "source": [
        "# Weapon Detection\n",
        "In this project , we will use a pre-trained YOLOv8 model to carry out object detection on images and videos. We will carry out object detection using PyTorch YOLOv8 using the models available in the Ultralytics YOLOv8 repository.\n",
        "\n",
        "![9.jpg](attachment:9.jpg)"
      ],
      "id": "4cd13875"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90b60299"
      },
      "source": [
        "### Install the ultralytics package using pip"
      ],
      "id": "90b60299"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53371565"
      },
      "source": [
        "![banner-yolov8.png](attachment:banner-yolov8.png)"
      ],
      "id": "53371565"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d22e0343",
        "outputId": "a884a327-5ffe-4c50-c6bd-fc05c5fbaaa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.175-py3-none-any.whl (616 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/616.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m112.6/616.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”\u001b[0m \u001b[32m553.0/616.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m616.3/616.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->ultralytics) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->ultralytics) (16.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: ultralytics\n",
            "Successfully installed ultralytics-8.0.175\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ],
      "id": "d22e0343"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ab1f46b1"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO"
      ],
      "id": "ab1f46b1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eea03ab"
      },
      "source": [
        "# Load a pretrained YOLO model"
      ],
      "id": "1eea03ab"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d57afd9",
        "outputId": "704e2eda-2cb7-44a7-dbc0-be8e45a98655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 15.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = YOLO(\"yolov8n.pt\")"
      ],
      "id": "4d57afd9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfe3049c"
      },
      "source": [
        "## Preparing The Dataset\n",
        "\n",
        "### Collect Images\n",
        "I collect my images from alot of sources like google , movies and youtube\n",
        "\n",
        "### Create Labels\n",
        "I used Make Sense to annotate the objects of interest to create a ground truth for your model to learn from."
      ],
      "id": "cfe3049c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "166fd6e4"
      },
      "source": [
        "![3981ea80-a62f-11e9-9815-cd3293dbdd22.png](attachment:3981ea80-a62f-11e9-9815-cd3293dbdd22.png)"
      ],
      "id": "166fd6e4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69a2445d"
      },
      "source": [
        "## Organize your training and validation images and labels as shown in the example below."
      ],
      "id": "69a2445d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91a9ad8b"
      },
      "source": [
        "![134436012-65111ad1-9541-4853-81a6-f19a3468b75f.png](attachment:134436012-65111ad1-9541-4853-81a6-f19a3468b75f.png)"
      ],
      "id": "91a9ad8b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7a4e638"
      },
      "source": [
        "# Change the data file 'coco128.yaml' parameters"
      ],
      "id": "e7a4e638"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7aca9ec"
      },
      "source": [
        "![Screenshot%202023-09-06%20092030.png](attachment:Screenshot%202023-09-06%20092030.png)"
      ],
      "id": "d7aca9ec"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13b4da73"
      },
      "source": [
        "# Train the model"
      ],
      "id": "13b4da73"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59daac16",
        "outputId": "cf8475a1-cce4-42db-e13f-b6c5d7086e47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.175 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=coco128.yaml, epochs=100, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "\n",
            "Dataset 'coco128.yaml' images not found âš ï¸, missing path '/content/datasets/coco128/images/train2017'\n",
            "Downloading https://ultralytics.com/assets/coco128.zip to '/content/datasets/coco128.zip'...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.66M/6.66M [00:00<00:00, 49.5MB/s]\n",
            "Unzipping /content/datasets/coco128.zip to /content/datasets/coco128...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 263/263 [00:00<00:00, 1323.93file/s]\n",
            "Dataset download success âœ… (1.3s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 37.5MB/s]\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 225 layers, 3157200 parameters, 3157184 gradients\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco128/labels/train2017... 126 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 1197.75it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/coco128/labels/train2017.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      1/100         0G      1.166      1.461      1.243        294        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [02:11<00:00, 16.39s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:37<00:00,  9.39s/it]\n",
            "                   all        128        929      0.629      0.549      0.596      0.443\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      2/100         0G      1.218      1.461       1.27        251        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:56<00:00, 14.60s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.60s/it]\n",
            "                   all        128        929      0.631      0.574      0.621      0.466\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      3/100         0G      1.119       1.36      1.212        158        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:54<00:00, 14.28s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:41<00:00, 10.34s/it]\n",
            "                   all        128        929      0.677      0.597      0.649      0.486\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      4/100         0G      1.124      1.262      1.211        256        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [02:00<00:00, 15.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.74s/it]\n",
            "                   all        128        929      0.692      0.612      0.662      0.497\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      5/100         0G      1.164      1.306      1.224        248        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:55<00:00, 14.40s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:40<00:00, 10.02s/it]\n",
            "                   all        128        929      0.696      0.621      0.679      0.506\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      6/100         0G      1.177      1.267      1.206        254        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:54<00:00, 14.34s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.91s/it]\n",
            "                   all        128        929      0.701      0.619      0.689      0.512\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      7/100         0G      1.106      1.163      1.189        236        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:53<00:00, 14.20s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:43<00:00, 10.83s/it]\n",
            "                   all        128        929       0.76      0.611        0.7      0.521\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      8/100         0G      1.125      1.131      1.188        190        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:55<00:00, 14.39s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.96s/it]\n",
            "                   all        128        929      0.768      0.627      0.719      0.538\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      9/100         0G      1.047      1.131      1.176        176        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:53<00:00, 14.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.93s/it]\n",
            "                   all        128        929      0.744      0.656      0.728       0.55\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     10/100         0G      1.077      1.122      1.165        214        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:55<00:00, 14.43s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.56s/it]\n",
            "                   all        128        929      0.745      0.666      0.736      0.555\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     11/100         0G      1.061      1.075       1.18        151        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:55<00:00, 14.46s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.90s/it]\n",
            "                   all        128        929      0.787      0.633      0.745      0.567\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     12/100         0G      1.079      1.076      1.166        214        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:59<00:00, 14.90s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.85s/it]\n",
            "                   all        128        929      0.785      0.647      0.757      0.574\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     13/100         0G      1.019      1.091      1.158        256        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:56<00:00, 14.53s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.93s/it]\n",
            "                   all        128        929      0.804      0.651      0.768      0.583\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     14/100         0G      1.082      1.045       1.15        239        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:58<00:00, 14.77s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:40<00:00, 10.05s/it]\n",
            "                   all        128        929      0.798       0.67      0.776      0.592\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     15/100         0G      1.027     0.9965      1.142        360        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:56<00:00, 14.57s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:41<00:00, 10.36s/it]\n",
            "                   all        128        929      0.812      0.682      0.784      0.605\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     16/100         0G      1.077      1.059      1.167        196        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:55<00:00, 14.42s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:40<00:00, 10.08s/it]\n",
            "                   all        128        929      0.813      0.692      0.779      0.606\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     17/100         0G      1.022      1.002      1.136        187        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:55<00:00, 14.39s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:40<00:00, 10.05s/it]\n",
            "                   all        128        929      0.818      0.687      0.795      0.611\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     18/100         0G      1.022     0.9817      1.138        208        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:55<00:00, 14.41s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.92s/it]\n",
            "                   all        128        929      0.843       0.69      0.802      0.618\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     19/100         0G      1.011      0.934      1.102        243        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:55<00:00, 14.42s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.71s/it]\n",
            "                   all        128        929      0.841      0.714      0.802      0.622\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     20/100         0G      1.028     0.9842      1.145        186        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:54<00:00, 14.32s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.81s/it]\n",
            "                   all        128        929      0.814       0.73      0.797      0.623\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     21/100         0G      1.007     0.9205      1.112        246        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:56<00:00, 14.51s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.91s/it]\n",
            "                   all        128        929      0.817      0.727        0.8      0.633\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     22/100         0G      1.007     0.9956      1.131        157        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:54<00:00, 14.35s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.62s/it]\n",
            "                   all        128        929      0.826      0.721       0.81      0.637\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     23/100         0G      1.004      0.927      1.119        212        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:56<00:00, 14.54s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.76s/it]\n",
            "                   all        128        929      0.857      0.712      0.812      0.643\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     24/100         0G      1.003      0.928      1.118        217        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:59<00:00, 14.90s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:40<00:00, 10.07s/it]\n",
            "                   all        128        929      0.874      0.708      0.813      0.646\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     25/100         0G     0.9645     0.8733      1.087        195        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:59<00:00, 14.95s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.96s/it]\n",
            "                   all        128        929       0.86       0.72      0.823       0.65\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     26/100         0G      0.986     0.8775      1.126        262        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:56<00:00, 14.57s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.54s/it]\n",
            "                   all        128        929      0.858      0.724      0.816      0.652\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     27/100         0G     0.9472     0.8853      1.091        217        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:58<00:00, 14.76s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:43<00:00, 10.79s/it]\n",
            "                   all        128        929      0.872      0.723       0.82      0.655\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     28/100         0G     0.9678     0.8717      1.072        229        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:57<00:00, 14.64s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:40<00:00, 10.09s/it]\n",
            "                   all        128        929      0.858      0.735      0.825      0.662\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     29/100         0G     0.9589     0.8854      1.095        267        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:57<00:00, 14.71s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.59s/it]\n",
            "                   all        128        929      0.845      0.751      0.826      0.668\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     30/100         0G     0.9241     0.8791      1.099        159        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:59<00:00, 14.96s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.99s/it]\n",
            "                   all        128        929      0.865       0.74       0.83      0.668\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     31/100         0G     0.9518     0.8439      1.103        191        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:56<00:00, 14.53s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.86s/it]\n",
            "                   all        128        929      0.879      0.727       0.84      0.668\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     32/100         0G       0.94     0.8355      1.093        228        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:55<00:00, 14.46s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.76s/it]\n",
            "                   all        128        929      0.845      0.747      0.845      0.672\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     33/100         0G     0.9619     0.8359      1.075        213        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:55<00:00, 14.41s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:40<00:00, 10.05s/it]\n",
            "                   all        128        929      0.875      0.735       0.85      0.679\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     34/100         0G     0.9258     0.7947      1.055        244        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:54<00:00, 14.35s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.78s/it]\n",
            "                   all        128        929      0.857      0.758      0.854      0.683\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     35/100         0G     0.8924     0.8181      1.082        200        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:53<00:00, 14.20s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.63s/it]\n",
            "                   all        128        929      0.776      0.824      0.856      0.687\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     36/100         0G     0.8916     0.8097      1.065        257        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:54<00:00, 14.33s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.56s/it]\n",
            "                   all        128        929      0.793      0.815      0.853      0.686\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     37/100         0G     0.9681      0.839      1.094        142        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:55<00:00, 14.49s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.87s/it]\n",
            "                   all        128        929      0.823      0.803      0.858      0.687\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     38/100         0G     0.9556      0.832      1.087        257        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:56<00:00, 14.61s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.93s/it]\n",
            "                   all        128        929      0.836      0.799      0.859      0.688\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     39/100         0G     0.9102     0.8053      1.074        212        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:55<00:00, 14.43s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.95s/it]\n",
            "                   all        128        929      0.832      0.806      0.861      0.691\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     40/100         0G     0.9541     0.8251      1.077        175        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:56<00:00, 14.52s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.59s/it]\n",
            "                   all        128        929      0.902      0.759      0.861      0.691\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     41/100         0G     0.8931     0.7977      1.067        196        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:55<00:00, 14.42s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.95s/it]\n",
            "                   all        128        929      0.886      0.777      0.864      0.696\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     42/100         0G     0.9309      0.811      1.078        191        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:56<00:00, 14.56s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.98s/it]\n",
            "                   all        128        929      0.892      0.774      0.863      0.696\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     43/100         0G      0.887     0.7627      1.053        186        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:55<00:00, 14.42s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:40<00:00, 10.09s/it]\n",
            "                   all        128        929      0.864      0.798      0.862      0.702\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     44/100         0G     0.9251      0.788      1.066        171        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [02:00<00:00, 15.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:40<00:00, 10.22s/it]\n",
            "                   all        128        929      0.846      0.809      0.865      0.703\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     45/100         0G      0.881     0.7907      1.051        263        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:56<00:00, 14.61s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.92s/it]\n",
            "                   all        128        929      0.844       0.81      0.861      0.704\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     46/100         0G     0.9132     0.7825      1.056        169        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:57<00:00, 14.69s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00, 10.00s/it]\n",
            "                   all        128        929      0.849      0.795      0.863      0.705\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     47/100         0G     0.8669     0.7916      1.068        189        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:58<00:00, 14.75s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.76s/it]\n",
            "                   all        128        929      0.905      0.773      0.865      0.708\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     48/100         0G     0.8785      0.765      1.052        213        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:58<00:00, 14.85s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.94s/it]\n",
            "                   all        128        929      0.918      0.764      0.866      0.707\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     49/100         0G     0.9364      0.799      1.064        249        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:56<00:00, 14.58s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.68s/it]\n",
            "                   all        128        929      0.924      0.761      0.866      0.709\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     50/100         0G     0.9169     0.7956      1.078        239        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:56<00:00, 14.53s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.58s/it]\n",
            "                   all        128        929      0.922       0.76      0.867      0.712\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     51/100         0G     0.8907     0.7475      1.059        250        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:56<00:00, 14.57s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.80s/it]\n",
            "                   all        128        929      0.839      0.808      0.867      0.714\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     52/100         0G      0.884     0.7741      1.061        217        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:58<00:00, 14.77s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.86s/it]\n",
            "                   all        128        929      0.853      0.799      0.867      0.713\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     53/100         0G     0.8428     0.7404      1.048        145        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:56<00:00, 14.58s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.74s/it]\n",
            "                   all        128        929      0.892      0.786      0.869      0.711\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     54/100         0G     0.8658     0.7253      1.049        152        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:55<00:00, 14.47s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:40<00:00, 10.21s/it]\n",
            "                   all        128        929       0.91      0.778       0.87      0.715\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     55/100         0G     0.8428     0.7136      1.029        288        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:57<00:00, 14.70s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:42<00:00, 10.58s/it]\n",
            "                   all        128        929      0.931      0.771      0.869      0.716\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     56/100         0G     0.9042     0.7621      1.052        185        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:58<00:00, 14.77s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.92s/it]\n",
            "                   all        128        929      0.926      0.773      0.868      0.714\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     57/100         0G     0.8943     0.7587      1.061        193        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:57<00:00, 14.65s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.69s/it]\n",
            "                   all        128        929      0.915      0.776      0.868      0.715\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     58/100         0G     0.8452     0.7598      1.055        203        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:57<00:00, 14.63s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.80s/it]\n",
            "                   all        128        929      0.917      0.779      0.871      0.715\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     59/100         0G      0.848     0.7135      1.036        235        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:57<00:00, 14.69s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.52s/it]\n",
            "                   all        128        929      0.899      0.791      0.871      0.718\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     60/100         0G     0.8561     0.7595      1.052        165        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:56<00:00, 14.59s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.68s/it]\n",
            "                   all        128        929      0.898      0.794      0.871      0.719\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     61/100         0G     0.8685     0.7275      1.033        160        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:57<00:00, 14.63s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.55s/it]\n",
            "                   all        128        929      0.908      0.789      0.872      0.719\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     62/100         0G     0.8629     0.7177      1.058        255        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:56<00:00, 14.53s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:37<00:00,  9.47s/it]\n",
            "                   all        128        929      0.911       0.79      0.872       0.72\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     63/100         0G     0.8645     0.7236      1.034        219        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:56<00:00, 14.59s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:41<00:00, 10.34s/it]\n",
            "                   all        128        929      0.921      0.791      0.875      0.723\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     64/100         0G     0.8823     0.7151      1.049        244        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:58<00:00, 14.83s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:40<00:00, 10.16s/it]\n",
            "                   all        128        929      0.913      0.797      0.876      0.724\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     65/100         0G     0.8544     0.7206      1.043        244        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:56<00:00, 14.53s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.79s/it]\n",
            "                   all        128        929       0.91      0.798      0.875      0.725\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     66/100         0G     0.8495     0.7334      1.029        299        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:56<00:00, 14.50s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.86s/it]\n",
            "                   all        128        929      0.907      0.804      0.878      0.728\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     67/100         0G     0.8514     0.7047      1.043        188        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:56<00:00, 14.60s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:41<00:00, 10.36s/it]\n",
            "                   all        128        929      0.913      0.801      0.879      0.729\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     68/100         0G      0.835     0.7086      1.027        183        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:55<00:00, 14.45s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.80s/it]\n",
            "                   all        128        929      0.909      0.805       0.88      0.731\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     69/100         0G     0.8537     0.7234      1.049        149        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:57<00:00, 14.74s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.89s/it]\n",
            "                   all        128        929      0.921      0.796       0.88      0.731\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     70/100         0G     0.8917     0.7571      1.042        250        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [02:03<00:00, 15.45s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:37<00:00,  9.41s/it]\n",
            "                   all        128        929      0.913      0.802      0.882      0.733\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     71/100         0G     0.8917     0.7375      1.042        153        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:55<00:00, 14.44s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.77s/it]\n",
            "                   all        128        929      0.907      0.806      0.881      0.733\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     72/100         0G     0.8539     0.7161      1.037        167        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:54<00:00, 14.36s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.73s/it]\n",
            "                   all        128        929      0.907      0.813      0.882      0.736\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     73/100         0G     0.8353     0.7096      1.029        222        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:54<00:00, 14.26s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:37<00:00,  9.27s/it]\n",
            "                   all        128        929       0.91      0.806      0.882      0.736\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     74/100         0G     0.8276     0.7002       1.02        203        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:53<00:00, 14.20s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:41<00:00, 10.30s/it]\n",
            "                   all        128        929      0.917      0.802      0.883      0.736\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     75/100         0G     0.8175     0.6924      1.017        213        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:53<00:00, 14.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00, 10.00s/it]\n",
            "                   all        128        929      0.913      0.806      0.883      0.738\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     76/100         0G     0.8753     0.7432      1.038        161        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:55<00:00, 14.49s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.94s/it]\n",
            "                   all        128        929      0.923      0.799      0.881      0.737\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     77/100         0G     0.8524     0.6989      1.036        175        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:53<00:00, 14.14s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.92s/it]\n",
            "                   all        128        929      0.923        0.8      0.881      0.737\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     78/100         0G     0.8451      0.717      1.031        153        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:55<00:00, 14.45s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:40<00:00, 10.07s/it]\n",
            "                   all        128        929      0.925      0.799      0.882      0.739\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     79/100         0G     0.8884      0.739      1.047        232        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:53<00:00, 14.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:37<00:00,  9.38s/it]\n",
            "                   all        128        929      0.931      0.798      0.883      0.739\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     80/100         0G     0.7934     0.6634      1.024        180        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:55<00:00, 14.41s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.57s/it]\n",
            "                   all        128        929      0.931      0.798      0.883      0.737\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     81/100         0G     0.8268     0.6764      1.013        299        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:54<00:00, 14.35s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:37<00:00,  9.27s/it]\n",
            "                   all        128        929      0.931      0.798      0.883      0.738\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     82/100         0G     0.8515     0.6957       1.03        209        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:53<00:00, 14.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.76s/it]\n",
            "                   all        128        929      0.923        0.8      0.884      0.737\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     83/100         0G     0.8699       0.75       1.05        245        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:52<00:00, 14.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:37<00:00,  9.44s/it]\n",
            "                   all        128        929      0.921      0.801      0.884      0.739\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     84/100         0G       0.87     0.7072      1.052        187        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:52<00:00, 14.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:41<00:00, 10.44s/it]\n",
            "                   all        128        929       0.92      0.801      0.885      0.739\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     85/100         0G     0.8269     0.6687      1.011        182        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:53<00:00, 14.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.64s/it]\n",
            "                   all        128        929      0.919      0.801      0.884      0.738\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     86/100         0G     0.8196     0.6872      1.032        238        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:53<00:00, 14.20s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.61s/it]\n",
            "                   all        128        929      0.923      0.799      0.884      0.738\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     87/100         0G     0.8132     0.6659      1.027        257        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:52<00:00, 14.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.83s/it]\n",
            "                   all        128        929      0.927      0.797      0.884      0.738\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     88/100         0G     0.8154     0.6535      1.022        218        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:55<00:00, 14.47s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.68s/it]\n",
            "                   all        128        929      0.928      0.797      0.883      0.738\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     89/100         0G     0.8335     0.6927      1.042        313        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:52<00:00, 14.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.54s/it]\n",
            "                   all        128        929      0.921      0.801      0.884      0.738\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     90/100         0G     0.8365     0.7041       1.02        227        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:53<00:00, 14.14s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.63s/it]\n",
            "                   all        128        929      0.929      0.798      0.883      0.739\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     91/100         0G     0.8591      0.758       1.02        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:53<00:00, 14.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.58s/it]\n",
            "                   all        128        929      0.929      0.792      0.883      0.738\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     92/100         0G     0.8482     0.6999     0.9979        101        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:50<00:00, 13.85s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:37<00:00,  9.42s/it]\n",
            "                   all        128        929      0.895      0.805      0.883      0.735\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     93/100         0G     0.8883       0.73      1.025        166        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:51<00:00, 13.88s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.57s/it]\n",
            "                   all        128        929      0.874      0.813      0.881      0.728\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     94/100         0G      0.855     0.7171      1.016        123        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:51<00:00, 13.93s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:40<00:00, 10.02s/it]\n",
            "                   all        128        929      0.859      0.816      0.877      0.725\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     95/100         0G     0.8654     0.7343      1.028        124        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:53<00:00, 14.18s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.83s/it]\n",
            "                   all        128        929      0.849      0.819      0.876      0.722\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     96/100         0G     0.8435     0.6753     0.9921        128        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:53<00:00, 14.15s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:37<00:00,  9.45s/it]\n",
            "                   all        128        929      0.844      0.822      0.876      0.722\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     97/100         0G      0.841     0.7015     0.9994        119        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:51<00:00, 13.94s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:36<00:00,  9.23s/it]\n",
            "                   all        128        929      0.827      0.829      0.875      0.719\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     98/100         0G     0.8367     0.6585       1.01        112        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:51<00:00, 13.93s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.61s/it]\n",
            "                   all        128        929      0.894       0.79      0.875      0.721\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     99/100         0G     0.7966      0.661      0.976        104        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:50<00:00, 13.77s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:37<00:00,  9.41s/it]\n",
            "                   all        128        929      0.897      0.788      0.874      0.724\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "    100/100         0G     0.8165      0.656     0.9967        127        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:50<00:00, 13.84s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.64s/it]\n",
            "                   all        128        929      0.894      0.789      0.874      0.721\n",
            "\n",
            "100 epochs completed in 4.326 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.175 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:35<00:00,  8.91s/it]\n",
            "                   all        128        929       0.92      0.801      0.886       0.74\n",
            "                person        128        254      0.984      0.705      0.885      0.703\n",
            "               bicycle        128          6      0.826        0.5      0.611      0.514\n",
            "                   car        128         46        0.9      0.393      0.663      0.351\n",
            "            motorcycle        128          5      0.935          1      0.995       0.96\n",
            "              airplane        128          6      0.958          1      0.995       0.93\n",
            "                   bus        128          7          1      0.788      0.995      0.852\n",
            "                 train        128          3      0.931          1      0.995      0.831\n",
            "                 truck        128         12      0.916        0.5      0.645      0.488\n",
            "                  boat        128          6          1      0.463      0.873      0.627\n",
            "         traffic light        128         14      0.875      0.286      0.386      0.244\n",
            "             stop sign        128          2      0.877          1      0.995      0.846\n",
            "                 bench        128          9      0.988      0.889      0.975      0.852\n",
            "                  bird        128         16          1      0.953      0.995      0.804\n",
            "                   cat        128          4      0.923          1      0.995      0.907\n",
            "                   dog        128          9      0.975          1      0.995      0.888\n",
            "                 horse        128          2      0.888          1      0.995      0.946\n",
            "              elephant        128         17      0.982      0.941      0.985      0.867\n",
            "                  bear        128          1          1          1      0.995      0.995\n",
            "                 zebra        128          4      0.923          1      0.995      0.995\n",
            "               giraffe        128          9      0.988          1      0.995      0.952\n",
            "              backpack        128          6      0.866      0.667      0.789      0.681\n",
            "              umbrella        128         18      0.977      0.944      0.975      0.828\n",
            "               handbag        128         19          1      0.511      0.714      0.511\n",
            "                   tie        128          7      0.926      0.857       0.86      0.728\n",
            "              suitcase        128          4       0.99          1      0.995      0.871\n",
            "               frisbee        128          5      0.858        0.8      0.801      0.755\n",
            "                  skis        128          1      0.821          1      0.995      0.895\n",
            "             snowboard        128          7      0.831      0.857      0.964      0.818\n",
            "           sports ball        128          6          1       0.57      0.674      0.414\n",
            "                  kite        128         10          1      0.251      0.738      0.347\n",
            "          baseball bat        128          4      0.847        0.5      0.849      0.423\n",
            "        baseball glove        128          7      0.922      0.429      0.438      0.362\n",
            "            skateboard        128          5      0.933        0.8      0.858      0.716\n",
            "         tennis racket        128          7          1      0.628      0.718      0.514\n",
            "                bottle        128         18          1      0.424      0.863      0.562\n",
            "            wine glass        128         16          1      0.471      0.796       0.56\n",
            "                   cup        128         36          1      0.681      0.918      0.667\n",
            "                  fork        128          6      0.956      0.833      0.875        0.7\n",
            "                 knife        128         16      0.908       0.62      0.787      0.522\n",
            "                 spoon        128         22       0.93      0.605      0.742      0.553\n",
            "                  bowl        128         28      0.957      0.797      0.862      0.761\n",
            "                banana        128          1      0.792          1      0.995      0.895\n",
            "              sandwich        128          2      0.862          1      0.995      0.995\n",
            "                orange        128          4      0.777          1      0.995      0.793\n",
            "              broccoli        128         11      0.888      0.364      0.646      0.449\n",
            "                carrot        128         24      0.947      0.746      0.926      0.694\n",
            "               hot dog        128          2      0.865          1      0.995      0.995\n",
            "                 pizza        128          5      0.917          1      0.995      0.935\n",
            "                 donut        128         14      0.952          1      0.995      0.934\n",
            "                  cake        128          4      0.923          1      0.995      0.931\n",
            "                 chair        128         35          1      0.694      0.893      0.685\n",
            "                 couch        128          6          1      0.786      0.995      0.815\n",
            "          potted plant        128         14          1      0.979      0.995       0.84\n",
            "                   bed        128          3      0.887          1      0.995      0.963\n",
            "          dining table        128         13      0.941          1      0.995       0.85\n",
            "                toilet        128          2      0.865          1      0.995      0.849\n",
            "                    tv        128          2       0.88          1      0.995      0.947\n",
            "                laptop        128          3      0.909          1      0.995      0.897\n",
            "                 mouse        128          2      0.764        0.5      0.502      0.351\n",
            "                remote        128          8      0.947       0.75      0.751      0.633\n",
            "            cell phone        128          8      0.861        0.5      0.631      0.451\n",
            "             microwave        128          3      0.853          1      0.995      0.865\n",
            "                  oven        128          5      0.793        0.8      0.761      0.682\n",
            "                  sink        128          6      0.803      0.833      0.955      0.688\n",
            "          refrigerator        128          5      0.918          1      0.995      0.942\n",
            "                  book        128         29      0.873      0.483      0.785       0.52\n",
            "                 clock        128          9      0.956      0.889      0.961      0.803\n",
            "                  vase        128          2      0.844          1      0.995      0.946\n",
            "              scissors        128          1      0.813          1      0.995      0.697\n",
            "            teddy bear        128         21       0.95      0.902      0.983      0.839\n",
            "            toothbrush        128          5      0.921          1      0.995      0.892\n",
            "Speed: 4.9ms preprocess, 245.0ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "results = model.train(data='coco128.yaml', epochs=100, imgsz=640)"
      ],
      "id": "59daac16"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2625a77"
      },
      "source": [
        "\n",
        "# load a trained model\n"
      ],
      "id": "d2625a77"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "71ce7c93"
      },
      "outputs": [],
      "source": [
        "model = YOLO('/content/runs/detect/train/weights/best.pt')"
      ],
      "id": "71ce7c93"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "823c33ae"
      },
      "source": [
        "# Model Predict"
      ],
      "id": "823c33ae"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5444bed9",
        "outputId": "3a36bcb4-0842-4c74-a709-7432679ce67b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 D:\\computer_vision\\object_detection\\weapon_detection\\9.jpg: 192x320 1 weapon, 87.4ms\n",
            "Speed: 3.0ms preprocess, 87.4ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 320)\n",
            "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'weapon'}\n",
              " orig_img: array([[[194, 174, 173],\n",
              "         [195, 175, 174],\n",
              "         [197, 176, 175],\n",
              "         ...,\n",
              "         [192, 169, 167],\n",
              "         [192, 169, 167],\n",
              "         [192, 169, 167]],\n",
              " \n",
              "        [[195, 175, 174],\n",
              "         [196, 176, 175],\n",
              "         [197, 176, 175],\n",
              "         ...,\n",
              "         [192, 169, 167],\n",
              "         [192, 169, 167],\n",
              "         [192, 169, 167]],\n",
              " \n",
              "        [[198, 177, 176],\n",
              "         [198, 177, 176],\n",
              "         [198, 177, 176],\n",
              "         ...,\n",
              "         [190, 169, 167],\n",
              "         [190, 169, 167],\n",
              "         [190, 169, 167]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[158, 165, 162],\n",
              "         [158, 165, 162],\n",
              "         [158, 165, 162],\n",
              "         ...,\n",
              "         [217, 214, 216],\n",
              "         [217, 214, 216],\n",
              "         [217, 214, 216]],\n",
              " \n",
              "        [[157, 164, 161],\n",
              "         [157, 164, 161],\n",
              "         [157, 164, 161],\n",
              "         ...,\n",
              "         [217, 214, 216],\n",
              "         [217, 214, 216],\n",
              "         [217, 214, 216]],\n",
              " \n",
              "        [[156, 163, 160],\n",
              "         [156, 163, 160],\n",
              "         [156, 163, 160],\n",
              "         ...,\n",
              "         [217, 214, 216],\n",
              "         [217, 214, 216],\n",
              "         [217, 214, 216]]], dtype=uint8)\n",
              " orig_shape: (641, 1140)\n",
              " path: 'D:\\\\computer_vision\\\\object_detection\\\\weapon_detection\\\\9.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs\\\\detect\\\\predict2'\n",
              " speed: {'preprocess': 2.9997825622558594, 'inference': 87.35084533691406, 'postprocess': 0.0}]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict('9.jpg', save=True,show=True, imgsz=320, conf=0.5)"
      ],
      "id": "5444bed9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aa5a218"
      },
      "source": [
        "# Plotting Results"
      ],
      "id": "8aa5a218"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f6c3016",
        "outputId": "52211ad7-e813-4c9c-b190-f6dc045cfa4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 D:\\computer_vision\\object_detection\\weapon_detection\\9.jpg: 384x640 2 weapons, 0.0ms\n",
            "Speed: 4.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "results = model('9.jpg')  # results list\n",
        "\n",
        "# Show the results\n",
        "for r in results:\n",
        "    im_array = r.plot()  # plot a BGR numpy array of predictions\n",
        "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
        "    im.show()  # show image\n",
        "    im.save('results2.jpg')  # save image"
      ],
      "id": "2f6c3016"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a68e2b2a"
      },
      "source": [
        "![results.jpg](attachment:results.jpg)"
      ],
      "id": "a68e2b2a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc7b9a38"
      },
      "source": [
        "# Here's a Python script using OpenCV (cv2) and YOLOv8 to run inference on video frames and save the video."
      ],
      "id": "fc7b9a38"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8e0a4ef0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f5bfede-2d28-4f75-9579-b76bb30b0cc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 544x640 1 person, 2 cars, 1 handbag, 530.5ms\n",
            "Speed: 3.9ms preprocess, 530.5ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 2 cars, 1074.2ms\n",
            "Speed: 8.4ms preprocess, 1074.2ms inference, 12.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 398.5ms\n",
            "Speed: 3.2ms preprocess, 398.5ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 325.1ms\n",
            "Speed: 3.3ms preprocess, 325.1ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 2 cars, 360.1ms\n",
            "Speed: 3.3ms preprocess, 360.1ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 322.9ms\n",
            "Speed: 3.4ms preprocess, 322.9ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 245.3ms\n",
            "Speed: 3.4ms preprocess, 245.3ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 2 cars, 212.8ms\n",
            "Speed: 3.5ms preprocess, 212.8ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 2 cars, 229.2ms\n",
            "Speed: 7.0ms preprocess, 229.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 209.9ms\n",
            "Speed: 3.4ms preprocess, 209.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 205.4ms\n",
            "Speed: 5.0ms preprocess, 205.4ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 199.7ms\n",
            "Speed: 2.6ms preprocess, 199.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 212.4ms\n",
            "Speed: 3.4ms preprocess, 212.4ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 2 cars, 205.6ms\n",
            "Speed: 3.4ms preprocess, 205.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 198.7ms\n",
            "Speed: 3.9ms preprocess, 198.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 198.3ms\n",
            "Speed: 3.4ms preprocess, 198.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 207.9ms\n",
            "Speed: 3.2ms preprocess, 207.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 210.0ms\n",
            "Speed: 3.3ms preprocess, 210.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 203.1ms\n",
            "Speed: 3.4ms preprocess, 203.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 206.6ms\n",
            "Speed: 3.5ms preprocess, 206.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 206.8ms\n",
            "Speed: 3.3ms preprocess, 206.8ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 202.8ms\n",
            "Speed: 3.2ms preprocess, 202.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 215.6ms\n",
            "Speed: 3.2ms preprocess, 215.6ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 210.4ms\n",
            "Speed: 3.3ms preprocess, 210.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 214.8ms\n",
            "Speed: 3.9ms preprocess, 214.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 198.4ms\n",
            "Speed: 5.2ms preprocess, 198.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 214.2ms\n",
            "Speed: 3.3ms preprocess, 214.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 207.8ms\n",
            "Speed: 3.3ms preprocess, 207.8ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 200.3ms\n",
            "Speed: 3.9ms preprocess, 200.3ms inference, 2.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 2 cars, 198.1ms\n",
            "Speed: 3.2ms preprocess, 198.1ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 2 cars, 197.2ms\n",
            "Speed: 3.2ms preprocess, 197.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 2 cars, 205.2ms\n",
            "Speed: 3.6ms preprocess, 205.2ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 2 cars, 189.5ms\n",
            "Speed: 3.1ms preprocess, 189.5ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 207.8ms\n",
            "Speed: 3.9ms preprocess, 207.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 192.3ms\n",
            "Speed: 3.3ms preprocess, 192.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 2 cars, 190.9ms\n",
            "Speed: 3.2ms preprocess, 190.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 205.0ms\n",
            "Speed: 3.1ms preprocess, 205.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 2 cars, 213.8ms\n",
            "Speed: 3.2ms preprocess, 213.8ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 195.1ms\n",
            "Speed: 3.2ms preprocess, 195.1ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 210.0ms\n",
            "Speed: 3.2ms preprocess, 210.0ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 209.9ms\n",
            "Speed: 3.2ms preprocess, 209.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 207.8ms\n",
            "Speed: 3.6ms preprocess, 207.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 201.2ms\n",
            "Speed: 3.3ms preprocess, 201.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 208.9ms\n",
            "Speed: 3.3ms preprocess, 208.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 2 cars, 199.0ms\n",
            "Speed: 3.1ms preprocess, 199.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 200.7ms\n",
            "Speed: 4.4ms preprocess, 200.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 205.2ms\n",
            "Speed: 3.2ms preprocess, 205.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 203.8ms\n",
            "Speed: 3.2ms preprocess, 203.8ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 201.9ms\n",
            "Speed: 3.3ms preprocess, 201.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 1 bird, 199.7ms\n",
            "Speed: 3.3ms preprocess, 199.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 handbag, 211.4ms\n",
            "Speed: 4.1ms preprocess, 211.4ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 256.5ms\n",
            "Speed: 3.0ms preprocess, 256.5ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 320.2ms\n",
            "Speed: 3.3ms preprocess, 320.2ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 330.4ms\n",
            "Speed: 3.2ms preprocess, 330.4ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 322.6ms\n",
            "Speed: 3.5ms preprocess, 322.6ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 323.6ms\n",
            "Speed: 3.2ms preprocess, 323.6ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 320.1ms\n",
            "Speed: 3.3ms preprocess, 320.1ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 319.7ms\n",
            "Speed: 7.4ms preprocess, 319.7ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 308.7ms\n",
            "Speed: 3.2ms preprocess, 308.7ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 311.3ms\n",
            "Speed: 3.3ms preprocess, 311.3ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 284.1ms\n",
            "Speed: 3.4ms preprocess, 284.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 194.6ms\n",
            "Speed: 3.5ms preprocess, 194.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 188.4ms\n",
            "Speed: 5.2ms preprocess, 188.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 207.9ms\n",
            "Speed: 3.9ms preprocess, 207.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 bench, 218.3ms\n",
            "Speed: 5.4ms preprocess, 218.3ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 bench, 198.1ms\n",
            "Speed: 3.2ms preprocess, 198.1ms inference, 3.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 bench, 197.4ms\n",
            "Speed: 3.2ms preprocess, 197.4ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 stop sign, 203.5ms\n",
            "Speed: 3.2ms preprocess, 203.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 stop sign, 220.9ms\n",
            "Speed: 3.1ms preprocess, 220.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 200.7ms\n",
            "Speed: 3.2ms preprocess, 200.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 handbag, 193.3ms\n",
            "Speed: 3.3ms preprocess, 193.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 202.2ms\n",
            "Speed: 3.8ms preprocess, 202.2ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 204.8ms\n",
            "Speed: 3.5ms preprocess, 204.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 203.4ms\n",
            "Speed: 4.8ms preprocess, 203.4ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 196.5ms\n",
            "Speed: 3.9ms preprocess, 196.5ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 192.1ms\n",
            "Speed: 3.3ms preprocess, 192.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 195.9ms\n",
            "Speed: 3.3ms preprocess, 195.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 193.2ms\n",
            "Speed: 4.9ms preprocess, 193.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 226.1ms\n",
            "Speed: 4.4ms preprocess, 226.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 199.0ms\n",
            "Speed: 3.3ms preprocess, 199.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 stop sign, 199.2ms\n",
            "Speed: 3.3ms preprocess, 199.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 205.7ms\n",
            "Speed: 3.2ms preprocess, 205.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 213.5ms\n",
            "Speed: 3.3ms preprocess, 213.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 197.7ms\n",
            "Speed: 2.9ms preprocess, 197.7ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 190.6ms\n",
            "Speed: 4.1ms preprocess, 190.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 210.5ms\n",
            "Speed: 4.1ms preprocess, 210.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 191.8ms\n",
            "Speed: 5.3ms preprocess, 191.8ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 218.4ms\n",
            "Speed: 3.3ms preprocess, 218.4ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 194.5ms\n",
            "Speed: 3.2ms preprocess, 194.5ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 190.6ms\n",
            "Speed: 2.8ms preprocess, 190.6ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 199.5ms\n",
            "Speed: 4.4ms preprocess, 199.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 car, 214.2ms\n",
            "Speed: 2.8ms preprocess, 214.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 211.3ms\n",
            "Speed: 3.3ms preprocess, 211.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 198.4ms\n",
            "Speed: 3.5ms preprocess, 198.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 car, 200.3ms\n",
            "Speed: 5.9ms preprocess, 200.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 208.1ms\n",
            "Speed: 3.6ms preprocess, 208.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 car, 210.6ms\n",
            "Speed: 3.7ms preprocess, 210.6ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 207.2ms\n",
            "Speed: 4.2ms preprocess, 207.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 195.7ms\n",
            "Speed: 3.3ms preprocess, 195.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 195.2ms\n",
            "Speed: 5.5ms preprocess, 195.2ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 199.9ms\n",
            "Speed: 5.7ms preprocess, 199.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 216.0ms\n",
            "Speed: 3.3ms preprocess, 216.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 206.3ms\n",
            "Speed: 4.5ms preprocess, 206.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 209.5ms\n",
            "Speed: 5.3ms preprocess, 209.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 204.2ms\n",
            "Speed: 3.5ms preprocess, 204.2ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 213.2ms\n",
            "Speed: 3.6ms preprocess, 213.2ms inference, 4.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 326.7ms\n",
            "Speed: 4.9ms preprocess, 326.7ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 308.6ms\n",
            "Speed: 4.1ms preprocess, 308.6ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 handbag, 319.7ms\n",
            "Speed: 3.4ms preprocess, 319.7ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 324.0ms\n",
            "Speed: 3.2ms preprocess, 324.0ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 306.8ms\n",
            "Speed: 3.4ms preprocess, 306.8ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 315.0ms\n",
            "Speed: 3.6ms preprocess, 315.0ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 322.6ms\n",
            "Speed: 3.2ms preprocess, 322.6ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 313.6ms\n",
            "Speed: 4.0ms preprocess, 313.6ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 323.3ms\n",
            "Speed: 3.4ms preprocess, 323.3ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 277.2ms\n",
            "Speed: 3.9ms preprocess, 277.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 200.2ms\n",
            "Speed: 3.2ms preprocess, 200.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 205.2ms\n",
            "Speed: 4.3ms preprocess, 205.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 201.8ms\n",
            "Speed: 3.3ms preprocess, 201.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 201.0ms\n",
            "Speed: 3.3ms preprocess, 201.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 218.0ms\n",
            "Speed: 3.3ms preprocess, 218.0ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 207.9ms\n",
            "Speed: 3.4ms preprocess, 207.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 211.7ms\n",
            "Speed: 3.3ms preprocess, 211.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 204.9ms\n",
            "Speed: 4.8ms preprocess, 204.9ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 208.8ms\n",
            "Speed: 3.9ms preprocess, 208.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 201.0ms\n",
            "Speed: 3.6ms preprocess, 201.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 201.4ms\n",
            "Speed: 3.2ms preprocess, 201.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 223.9ms\n",
            "Speed: 3.6ms preprocess, 223.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 208.3ms\n",
            "Speed: 3.9ms preprocess, 208.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 219.6ms\n",
            "Speed: 3.7ms preprocess, 219.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 201.4ms\n",
            "Speed: 2.7ms preprocess, 201.4ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 204.1ms\n",
            "Speed: 4.0ms preprocess, 204.1ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 200.7ms\n",
            "Speed: 3.5ms preprocess, 200.7ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 199.2ms\n",
            "Speed: 3.5ms preprocess, 199.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 192.0ms\n",
            "Speed: 3.5ms preprocess, 192.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 195.1ms\n",
            "Speed: 4.4ms preprocess, 195.1ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 193.2ms\n",
            "Speed: 2.7ms preprocess, 193.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 203.4ms\n",
            "Speed: 3.3ms preprocess, 203.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 198.6ms\n",
            "Speed: 3.4ms preprocess, 198.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 200.6ms\n",
            "Speed: 5.8ms preprocess, 200.6ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 202.4ms\n",
            "Speed: 3.3ms preprocess, 202.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 198.6ms\n",
            "Speed: 5.4ms preprocess, 198.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 198.9ms\n",
            "Speed: 3.3ms preprocess, 198.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 203.4ms\n",
            "Speed: 3.9ms preprocess, 203.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 206.2ms\n",
            "Speed: 5.0ms preprocess, 206.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 208.7ms\n",
            "Speed: 4.0ms preprocess, 208.7ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 199.3ms\n",
            "Speed: 3.7ms preprocess, 199.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 202.8ms\n",
            "Speed: 3.3ms preprocess, 202.8ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 210.1ms\n",
            "Speed: 3.2ms preprocess, 210.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 200.8ms\n",
            "Speed: 3.3ms preprocess, 200.8ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 210.5ms\n",
            "Speed: 3.5ms preprocess, 210.5ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 204.2ms\n",
            "Speed: 3.5ms preprocess, 204.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 207.7ms\n",
            "Speed: 3.4ms preprocess, 207.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 201.8ms\n",
            "Speed: 3.5ms preprocess, 201.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 209.8ms\n",
            "Speed: 5.1ms preprocess, 209.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 221.6ms\n",
            "Speed: 3.4ms preprocess, 221.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 202.0ms\n",
            "Speed: 3.3ms preprocess, 202.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 214.8ms\n",
            "Speed: 5.1ms preprocess, 214.8ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 200.2ms\n",
            "Speed: 3.2ms preprocess, 200.2ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 197.5ms\n",
            "Speed: 3.3ms preprocess, 197.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 219.5ms\n",
            "Speed: 5.4ms preprocess, 219.5ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 319.8ms\n",
            "Speed: 3.3ms preprocess, 319.8ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 305.8ms\n",
            "Speed: 3.1ms preprocess, 305.8ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 317.3ms\n",
            "Speed: 3.2ms preprocess, 317.3ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 322.3ms\n",
            "Speed: 7.4ms preprocess, 322.3ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 315.6ms\n",
            "Speed: 4.2ms preprocess, 315.6ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 315.2ms\n",
            "Speed: 3.9ms preprocess, 315.2ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 330.6ms\n",
            "Speed: 3.2ms preprocess, 330.6ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 325.1ms\n",
            "Speed: 3.9ms preprocess, 325.1ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 321.5ms\n",
            "Speed: 3.4ms preprocess, 321.5ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 263.5ms\n",
            "Speed: 3.5ms preprocess, 263.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 219.5ms\n",
            "Speed: 3.8ms preprocess, 219.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 199.1ms\n",
            "Speed: 3.6ms preprocess, 199.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 198.1ms\n",
            "Speed: 3.8ms preprocess, 198.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 207.5ms\n",
            "Speed: 3.5ms preprocess, 207.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 213.7ms\n",
            "Speed: 3.4ms preprocess, 213.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 207.0ms\n",
            "Speed: 3.8ms preprocess, 207.0ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 210.5ms\n",
            "Speed: 3.3ms preprocess, 210.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 198.8ms\n",
            "Speed: 3.7ms preprocess, 198.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 201.9ms\n",
            "Speed: 3.3ms preprocess, 201.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 232.4ms\n",
            "Speed: 4.7ms preprocess, 232.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 199.0ms\n",
            "Speed: 3.8ms preprocess, 199.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 199.3ms\n",
            "Speed: 3.2ms preprocess, 199.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 196.3ms\n",
            "Speed: 3.3ms preprocess, 196.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 203.0ms\n",
            "Speed: 3.4ms preprocess, 203.0ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 stop sign, 204.1ms\n",
            "Speed: 4.8ms preprocess, 204.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 193.2ms\n",
            "Speed: 3.3ms preprocess, 193.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 199.1ms\n",
            "Speed: 5.4ms preprocess, 199.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 199.7ms\n",
            "Speed: 5.5ms preprocess, 199.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 207.8ms\n",
            "Speed: 5.2ms preprocess, 207.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 205.9ms\n",
            "Speed: 3.4ms preprocess, 205.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 208.5ms\n",
            "Speed: 3.4ms preprocess, 208.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 207.4ms\n",
            "Speed: 6.7ms preprocess, 207.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 213.6ms\n",
            "Speed: 3.6ms preprocess, 213.6ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 220.0ms\n",
            "Speed: 3.2ms preprocess, 220.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 205.0ms\n",
            "Speed: 3.2ms preprocess, 205.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 207.3ms\n",
            "Speed: 6.1ms preprocess, 207.3ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 202.5ms\n",
            "Speed: 3.4ms preprocess, 202.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 218.2ms\n",
            "Speed: 3.4ms preprocess, 218.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 202.4ms\n",
            "Speed: 3.4ms preprocess, 202.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 203.5ms\n",
            "Speed: 3.6ms preprocess, 203.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 217.0ms\n",
            "Speed: 3.6ms preprocess, 217.0ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 199.6ms\n",
            "Speed: 3.7ms preprocess, 199.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 226.1ms\n",
            "Speed: 3.6ms preprocess, 226.1ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 210.7ms\n",
            "Speed: 2.7ms preprocess, 210.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 207.0ms\n",
            "Speed: 3.7ms preprocess, 207.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 199.9ms\n",
            "Speed: 3.7ms preprocess, 199.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 211.0ms\n",
            "Speed: 4.6ms preprocess, 211.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 201.6ms\n",
            "Speed: 3.2ms preprocess, 201.6ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 203.4ms\n",
            "Speed: 3.2ms preprocess, 203.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 209.1ms\n",
            "Speed: 5.0ms preprocess, 209.1ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 218.3ms\n",
            "Speed: 3.2ms preprocess, 218.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 219.6ms\n",
            "Speed: 3.4ms preprocess, 219.6ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 200.7ms\n",
            "Speed: 3.2ms preprocess, 200.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 217.1ms\n",
            "Speed: 3.3ms preprocess, 217.1ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 334.0ms\n",
            "Speed: 4.6ms preprocess, 334.0ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 340.7ms\n",
            "Speed: 3.3ms preprocess, 340.7ms inference, 2.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 331.3ms\n",
            "Speed: 3.7ms preprocess, 331.3ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 327.5ms\n",
            "Speed: 3.3ms preprocess, 327.5ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 329.0ms\n",
            "Speed: 7.8ms preprocess, 329.0ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 315.0ms\n",
            "Speed: 3.2ms preprocess, 315.0ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 308.9ms\n",
            "Speed: 3.2ms preprocess, 308.9ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 320.9ms\n",
            "Speed: 6.0ms preprocess, 320.9ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 295.2ms\n",
            "Speed: 3.2ms preprocess, 295.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 187.2ms\n",
            "Speed: 3.3ms preprocess, 187.2ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 206.1ms\n",
            "Speed: 2.7ms preprocess, 206.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 208.0ms\n",
            "Speed: 3.4ms preprocess, 208.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 199.4ms\n",
            "Speed: 5.8ms preprocess, 199.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 198.2ms\n",
            "Speed: 3.2ms preprocess, 198.2ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 224.2ms\n",
            "Speed: 3.3ms preprocess, 224.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 208.3ms\n",
            "Speed: 3.8ms preprocess, 208.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 202.3ms\n",
            "Speed: 3.3ms preprocess, 202.3ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 206.6ms\n",
            "Speed: 3.4ms preprocess, 206.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 207.8ms\n",
            "Speed: 3.2ms preprocess, 207.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 200.7ms\n",
            "Speed: 4.5ms preprocess, 200.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 220.2ms\n",
            "Speed: 4.8ms preprocess, 220.2ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 207.3ms\n",
            "Speed: 2.8ms preprocess, 207.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 209.7ms\n",
            "Speed: 3.7ms preprocess, 209.7ms inference, 2.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 204.5ms\n",
            "Speed: 5.5ms preprocess, 204.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 197.0ms\n",
            "Speed: 3.4ms preprocess, 197.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 212.7ms\n",
            "Speed: 3.2ms preprocess, 212.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 197.9ms\n",
            "Speed: 3.6ms preprocess, 197.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 271.1ms\n",
            "Speed: 3.0ms preprocess, 271.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 199.7ms\n",
            "Speed: 3.5ms preprocess, 199.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 212.5ms\n",
            "Speed: 3.5ms preprocess, 212.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 211.1ms\n",
            "Speed: 3.4ms preprocess, 211.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 197.4ms\n",
            "Speed: 3.6ms preprocess, 197.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 197.2ms\n",
            "Speed: 3.3ms preprocess, 197.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 193.9ms\n",
            "Speed: 3.7ms preprocess, 193.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 205.5ms\n",
            "Speed: 3.8ms preprocess, 205.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 191.8ms\n",
            "Speed: 3.8ms preprocess, 191.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 205.7ms\n",
            "Speed: 3.7ms preprocess, 205.7ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 194.4ms\n",
            "Speed: 3.6ms preprocess, 194.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 197.7ms\n",
            "Speed: 3.8ms preprocess, 197.7ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 190.9ms\n",
            "Speed: 3.7ms preprocess, 190.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 1 tie, 195.9ms\n",
            "Speed: 3.2ms preprocess, 195.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 197.0ms\n",
            "Speed: 3.2ms preprocess, 197.0ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 1 tie, 205.6ms\n",
            "Speed: 3.7ms preprocess, 205.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 212.0ms\n",
            "Speed: 3.2ms preprocess, 212.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 201.9ms\n",
            "Speed: 3.3ms preprocess, 201.9ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 199.5ms\n",
            "Speed: 3.3ms preprocess, 199.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 201.1ms\n",
            "Speed: 3.3ms preprocess, 201.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 209.1ms\n",
            "Speed: 3.1ms preprocess, 209.1ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 207.7ms\n",
            "Speed: 3.3ms preprocess, 207.7ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 205.3ms\n",
            "Speed: 2.8ms preprocess, 205.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 204.3ms\n",
            "Speed: 3.4ms preprocess, 204.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 198.4ms\n",
            "Speed: 5.3ms preprocess, 198.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 211.7ms\n",
            "Speed: 9.8ms preprocess, 211.7ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 209.0ms\n",
            "Speed: 3.7ms preprocess, 209.0ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 316.6ms\n",
            "Speed: 3.3ms preprocess, 316.6ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 309.8ms\n",
            "Speed: 3.4ms preprocess, 309.8ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 316.0ms\n",
            "Speed: 3.1ms preprocess, 316.0ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 313.2ms\n",
            "Speed: 3.3ms preprocess, 313.2ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 ties, 311.8ms\n",
            "Speed: 3.2ms preprocess, 311.8ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 ties, 312.3ms\n",
            "Speed: 3.3ms preprocess, 312.3ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 ties, 316.9ms\n",
            "Speed: 3.3ms preprocess, 316.9ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 308.9ms\n",
            "Speed: 3.3ms preprocess, 308.9ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 331.1ms\n",
            "Speed: 3.4ms preprocess, 331.1ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 289.1ms\n",
            "Speed: 5.1ms preprocess, 289.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 204.4ms\n",
            "Speed: 3.2ms preprocess, 204.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 197.7ms\n",
            "Speed: 3.4ms preprocess, 197.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 ties, 220.7ms\n",
            "Speed: 3.2ms preprocess, 220.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 214.7ms\n",
            "Speed: 4.0ms preprocess, 214.7ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 199.3ms\n",
            "Speed: 4.6ms preprocess, 199.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 209.0ms\n",
            "Speed: 2.8ms preprocess, 209.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 1 tie, 205.6ms\n",
            "Speed: 3.2ms preprocess, 205.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 2 ties, 212.9ms\n",
            "Speed: 5.5ms preprocess, 212.9ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 202.1ms\n",
            "Speed: 3.2ms preprocess, 202.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 199.3ms\n",
            "Speed: 4.2ms preprocess, 199.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 ties, 196.9ms\n",
            "Speed: 6.2ms preprocess, 196.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 220.4ms\n",
            "Speed: 3.2ms preprocess, 220.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 205.7ms\n",
            "Speed: 3.3ms preprocess, 205.7ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 205.8ms\n",
            "Speed: 4.7ms preprocess, 205.8ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 1 tie, 203.4ms\n",
            "Speed: 3.4ms preprocess, 203.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 handbag, 2 ties, 211.5ms\n",
            "Speed: 3.3ms preprocess, 211.5ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 217.3ms\n",
            "Speed: 3.3ms preprocess, 217.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 222.4ms\n",
            "Speed: 3.4ms preprocess, 222.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 199.9ms\n",
            "Speed: 5.5ms preprocess, 199.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 200.7ms\n",
            "Speed: 3.3ms preprocess, 200.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 ties, 207.9ms\n",
            "Speed: 3.3ms preprocess, 207.9ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 210.5ms\n",
            "Speed: 3.1ms preprocess, 210.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 handbag, 1 tie, 193.3ms\n",
            "Speed: 3.3ms preprocess, 193.3ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 199.0ms\n",
            "Speed: 2.6ms preprocess, 199.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 2 ties, 200.8ms\n",
            "Speed: 2.7ms preprocess, 200.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 ties, 208.2ms\n",
            "Speed: 3.8ms preprocess, 208.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 1 tie, 193.8ms\n",
            "Speed: 4.4ms preprocess, 193.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 tie, 194.0ms\n",
            "Speed: 4.3ms preprocess, 194.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 tie, 187.7ms\n",
            "Speed: 3.5ms preprocess, 187.7ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 198.0ms\n",
            "Speed: 3.3ms preprocess, 198.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 217.8ms\n",
            "Speed: 3.2ms preprocess, 217.8ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 200.3ms\n",
            "Speed: 9.9ms preprocess, 200.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 217.7ms\n",
            "Speed: 3.2ms preprocess, 217.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 dog, 1 handbag, 206.3ms\n",
            "Speed: 4.6ms preprocess, 206.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 215.3ms\n",
            "Speed: 4.7ms preprocess, 215.3ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 206.2ms\n",
            "Speed: 4.1ms preprocess, 206.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 199.8ms\n",
            "Speed: 4.4ms preprocess, 199.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 199.1ms\n",
            "Speed: 3.7ms preprocess, 199.1ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 219.2ms\n",
            "Speed: 3.9ms preprocess, 219.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 215.3ms\n",
            "Speed: 3.7ms preprocess, 215.3ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 dog, 204.4ms\n",
            "Speed: 3.5ms preprocess, 204.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 199.4ms\n",
            "Speed: 3.4ms preprocess, 199.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 dog, 207.3ms\n",
            "Speed: 3.3ms preprocess, 207.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 208.0ms\n",
            "Speed: 4.3ms preprocess, 208.0ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 258.6ms\n",
            "Speed: 3.6ms preprocess, 258.6ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 bench, 312.4ms\n",
            "Speed: 4.7ms preprocess, 312.4ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 309.0ms\n",
            "Speed: 3.2ms preprocess, 309.0ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 318.4ms\n",
            "Speed: 3.1ms preprocess, 318.4ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 331.5ms\n",
            "Speed: 3.9ms preprocess, 331.5ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 313.4ms\n",
            "Speed: 3.3ms preprocess, 313.4ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 323.4ms\n",
            "Speed: 3.2ms preprocess, 323.4ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 1 dog, 322.5ms\n",
            "Speed: 3.3ms preprocess, 322.5ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 325.2ms\n",
            "Speed: 3.4ms preprocess, 325.2ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 bench, 322.4ms\n",
            "Speed: 3.3ms preprocess, 322.4ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 220.8ms\n",
            "Speed: 3.4ms preprocess, 220.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 204.4ms\n",
            "Speed: 3.3ms preprocess, 204.4ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 209.7ms\n",
            "Speed: 3.4ms preprocess, 209.7ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 210.4ms\n",
            "Speed: 3.2ms preprocess, 210.4ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 dog, 196.5ms\n",
            "Speed: 3.1ms preprocess, 196.5ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 193.3ms\n",
            "Speed: 3.1ms preprocess, 193.3ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 207.3ms\n",
            "Speed: 3.2ms preprocess, 207.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 189.4ms\n",
            "Speed: 3.7ms preprocess, 189.4ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 bench, 213.8ms\n",
            "Speed: 3.5ms preprocess, 213.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 195.2ms\n",
            "Speed: 5.0ms preprocess, 195.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 195.0ms\n",
            "Speed: 5.3ms preprocess, 195.0ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 203.7ms\n",
            "Speed: 3.1ms preprocess, 203.7ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 208.8ms\n",
            "Speed: 3.3ms preprocess, 208.8ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 202.4ms\n",
            "Speed: 5.3ms preprocess, 202.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 195.9ms\n",
            "Speed: 6.6ms preprocess, 195.9ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 197.6ms\n",
            "Speed: 3.3ms preprocess, 197.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 207.7ms\n",
            "Speed: 3.2ms preprocess, 207.7ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 198.9ms\n",
            "Speed: 3.3ms preprocess, 198.9ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 211.5ms\n",
            "Speed: 3.2ms preprocess, 211.5ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 202.3ms\n",
            "Speed: 4.4ms preprocess, 202.3ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 209.1ms\n",
            "Speed: 3.3ms preprocess, 209.1ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 212.3ms\n",
            "Speed: 3.4ms preprocess, 212.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 208.8ms\n",
            "Speed: 3.3ms preprocess, 208.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 203.3ms\n",
            "Speed: 5.9ms preprocess, 203.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 209.4ms\n",
            "Speed: 3.3ms preprocess, 209.4ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 199.1ms\n",
            "Speed: 4.2ms preprocess, 199.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 209.5ms\n",
            "Speed: 4.1ms preprocess, 209.5ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 213.1ms\n",
            "Speed: 4.9ms preprocess, 213.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 200.6ms\n",
            "Speed: 3.2ms preprocess, 200.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 212.5ms\n",
            "Speed: 3.2ms preprocess, 212.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 207.5ms\n",
            "Speed: 3.4ms preprocess, 207.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 208.1ms\n",
            "Speed: 2.7ms preprocess, 208.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 197.1ms\n",
            "Speed: 7.3ms preprocess, 197.1ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 211.8ms\n",
            "Speed: 3.4ms preprocess, 211.8ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 205.1ms\n",
            "Speed: 3.3ms preprocess, 205.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 195.6ms\n",
            "Speed: 3.4ms preprocess, 195.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 220.7ms\n",
            "Speed: 5.7ms preprocess, 220.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 handbag, 209.9ms\n",
            "Speed: 3.9ms preprocess, 209.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 208.2ms\n",
            "Speed: 3.9ms preprocess, 208.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 201.7ms\n",
            "Speed: 3.7ms preprocess, 201.7ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 196.0ms\n",
            "Speed: 3.5ms preprocess, 196.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 200.1ms\n",
            "Speed: 3.5ms preprocess, 200.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 199.1ms\n",
            "Speed: 3.4ms preprocess, 199.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 206.8ms\n",
            "Speed: 3.1ms preprocess, 206.8ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 197.4ms\n",
            "Speed: 3.6ms preprocess, 197.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 249.8ms\n",
            "Speed: 3.6ms preprocess, 249.8ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 306.9ms\n",
            "Speed: 5.8ms preprocess, 306.9ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 311.1ms\n",
            "Speed: 3.2ms preprocess, 311.1ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 handbag, 313.4ms\n",
            "Speed: 3.2ms preprocess, 313.4ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 317.4ms\n",
            "Speed: 6.7ms preprocess, 317.4ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 324.5ms\n",
            "Speed: 3.4ms preprocess, 324.5ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 323.5ms\n",
            "Speed: 3.2ms preprocess, 323.5ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 328.1ms\n",
            "Speed: 3.6ms preprocess, 328.1ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 322.8ms\n",
            "Speed: 3.5ms preprocess, 322.8ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 313.7ms\n",
            "Speed: 3.4ms preprocess, 313.7ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 handbag, 218.2ms\n",
            "Speed: 3.4ms preprocess, 218.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 204.5ms\n",
            "Speed: 3.3ms preprocess, 204.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 202.4ms\n",
            "Speed: 3.6ms preprocess, 202.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 204.0ms\n",
            "Speed: 3.7ms preprocess, 204.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 205.5ms\n",
            "Speed: 3.8ms preprocess, 205.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 203.4ms\n",
            "Speed: 3.7ms preprocess, 203.4ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 handbags, 194.9ms\n",
            "Speed: 4.1ms preprocess, 194.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 206.6ms\n",
            "Speed: 3.6ms preprocess, 206.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 handbag, 201.9ms\n",
            "Speed: 3.2ms preprocess, 201.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 209.2ms\n",
            "Speed: 5.1ms preprocess, 209.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 190.5ms\n",
            "Speed: 3.4ms preprocess, 190.5ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 handbag, 216.6ms\n",
            "Speed: 3.7ms preprocess, 216.6ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 197.7ms\n",
            "Speed: 3.2ms preprocess, 197.7ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 193.1ms\n",
            "Speed: 3.2ms preprocess, 193.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 245.6ms\n",
            "Speed: 3.3ms preprocess, 245.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 handbags, 202.9ms\n",
            "Speed: 3.3ms preprocess, 202.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 197.9ms\n",
            "Speed: 3.3ms preprocess, 197.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 197.6ms\n",
            "Speed: 4.6ms preprocess, 197.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 2 handbags, 216.5ms\n",
            "Speed: 5.3ms preprocess, 216.5ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 handbags, 199.3ms\n",
            "Speed: 3.8ms preprocess, 199.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 2 handbags, 201.3ms\n",
            "Speed: 3.1ms preprocess, 201.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 211.4ms\n",
            "Speed: 3.1ms preprocess, 211.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 203.4ms\n",
            "Speed: 3.3ms preprocess, 203.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 212.0ms\n",
            "Speed: 3.3ms preprocess, 212.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 214.0ms\n",
            "Speed: 3.2ms preprocess, 214.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 195.5ms\n",
            "Speed: 5.5ms preprocess, 195.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 198.3ms\n",
            "Speed: 2.7ms preprocess, 198.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 196.3ms\n",
            "Speed: 3.3ms preprocess, 196.3ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 211.7ms\n",
            "Speed: 4.2ms preprocess, 211.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 196.6ms\n",
            "Speed: 6.9ms preprocess, 196.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 203.2ms\n",
            "Speed: 5.0ms preprocess, 203.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 201.1ms\n",
            "Speed: 3.2ms preprocess, 201.1ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 219.7ms\n",
            "Speed: 4.1ms preprocess, 219.7ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 handbag, 200.7ms\n",
            "Speed: 3.2ms preprocess, 200.7ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 196.7ms\n",
            "Speed: 3.1ms preprocess, 196.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 196.7ms\n",
            "Speed: 3.3ms preprocess, 196.7ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 handbag, 197.1ms\n",
            "Speed: 3.1ms preprocess, 197.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 211.0ms\n",
            "Speed: 3.2ms preprocess, 211.0ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 196.9ms\n",
            "Speed: 3.5ms preprocess, 196.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 189.3ms\n",
            "Speed: 3.5ms preprocess, 189.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 handbag, 197.7ms\n",
            "Speed: 3.8ms preprocess, 197.7ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 200.8ms\n",
            "Speed: 9.3ms preprocess, 200.8ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 216.0ms\n",
            "Speed: 4.0ms preprocess, 216.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 193.8ms\n",
            "Speed: 3.6ms preprocess, 193.8ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 203.7ms\n",
            "Speed: 3.7ms preprocess, 203.7ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 259.2ms\n",
            "Speed: 3.7ms preprocess, 259.2ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 handbag, 336.2ms\n",
            "Speed: 3.8ms preprocess, 336.2ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 335.5ms\n",
            "Speed: 3.7ms preprocess, 335.5ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 321.1ms\n",
            "Speed: 4.5ms preprocess, 321.1ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 327.4ms\n",
            "Speed: 3.4ms preprocess, 327.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 318.9ms\n",
            "Speed: 3.3ms preprocess, 318.9ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 314.7ms\n",
            "Speed: 3.2ms preprocess, 314.7ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 323.8ms\n",
            "Speed: 3.1ms preprocess, 323.8ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 308.3ms\n",
            "Speed: 3.3ms preprocess, 308.3ms inference, 3.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 307.3ms\n",
            "Speed: 3.3ms preprocess, 307.3ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 230.1ms\n",
            "Speed: 3.3ms preprocess, 230.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 209.0ms\n",
            "Speed: 3.4ms preprocess, 209.0ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 194.8ms\n",
            "Speed: 3.2ms preprocess, 194.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 bench, 1 dog, 193.8ms\n",
            "Speed: 3.3ms preprocess, 193.8ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 192.4ms\n",
            "Speed: 3.3ms preprocess, 192.4ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 217.4ms\n",
            "Speed: 3.6ms preprocess, 217.4ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 201.7ms\n",
            "Speed: 3.5ms preprocess, 201.7ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 213.3ms\n",
            "Speed: 3.8ms preprocess, 213.3ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 228.8ms\n",
            "Speed: 3.4ms preprocess, 228.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 206.8ms\n",
            "Speed: 3.3ms preprocess, 206.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 213.4ms\n",
            "Speed: 3.5ms preprocess, 213.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 202.5ms\n",
            "Speed: 3.4ms preprocess, 202.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 210.2ms\n",
            "Speed: 5.1ms preprocess, 210.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 213.2ms\n",
            "Speed: 3.2ms preprocess, 213.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 221.1ms\n",
            "Speed: 3.3ms preprocess, 221.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 208.5ms\n",
            "Speed: 3.9ms preprocess, 208.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 214.2ms\n",
            "Speed: 4.1ms preprocess, 214.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 200.2ms\n",
            "Speed: 7.4ms preprocess, 200.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 202.7ms\n",
            "Speed: 3.3ms preprocess, 202.7ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 211.7ms\n",
            "Speed: 3.3ms preprocess, 211.7ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 203.8ms\n",
            "Speed: 3.6ms preprocess, 203.8ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 200.6ms\n",
            "Speed: 3.2ms preprocess, 200.6ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 214.8ms\n",
            "Speed: 5.8ms preprocess, 214.8ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 212.3ms\n",
            "Speed: 3.3ms preprocess, 212.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 205.7ms\n",
            "Speed: 7.2ms preprocess, 205.7ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 203.7ms\n",
            "Speed: 3.7ms preprocess, 203.7ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 210.8ms\n",
            "Speed: 3.5ms preprocess, 210.8ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 202.9ms\n",
            "Speed: 4.1ms preprocess, 202.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 207.0ms\n",
            "Speed: 3.6ms preprocess, 207.0ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 206.2ms\n",
            "Speed: 3.8ms preprocess, 206.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 200.9ms\n",
            "Speed: 3.4ms preprocess, 200.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 191.7ms\n",
            "Speed: 4.1ms preprocess, 191.7ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 202.1ms\n",
            "Speed: 3.3ms preprocess, 202.1ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 205.0ms\n",
            "Speed: 3.7ms preprocess, 205.0ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 193.1ms\n",
            "Speed: 3.4ms preprocess, 193.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 195.7ms\n",
            "Speed: 4.6ms preprocess, 195.7ms inference, 3.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 201.9ms\n",
            "Speed: 3.1ms preprocess, 201.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 bench, 199.1ms\n",
            "Speed: 3.4ms preprocess, 199.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 dog, 193.4ms\n",
            "Speed: 2.7ms preprocess, 193.4ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 197.8ms\n",
            "Speed: 3.2ms preprocess, 197.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 215.7ms\n",
            "Speed: 3.2ms preprocess, 215.7ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 210.2ms\n",
            "Speed: 4.2ms preprocess, 210.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 208.1ms\n",
            "Speed: 3.3ms preprocess, 208.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 dog, 198.4ms\n",
            "Speed: 4.0ms preprocess, 198.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 209.0ms\n",
            "Speed: 3.3ms preprocess, 209.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 290.0ms\n",
            "Speed: 3.2ms preprocess, 290.0ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 316.1ms\n",
            "Speed: 3.4ms preprocess, 316.1ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 333.0ms\n",
            "Speed: 3.3ms preprocess, 333.0ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 479.6ms\n",
            "Speed: 3.3ms preprocess, 479.6ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 333.7ms\n",
            "Speed: 3.2ms preprocess, 333.7ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 324.2ms\n",
            "Speed: 3.2ms preprocess, 324.2ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 dog, 325.1ms\n",
            "Speed: 3.3ms preprocess, 325.1ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 334.6ms\n",
            "Speed: 3.3ms preprocess, 334.6ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 321.3ms\n",
            "Speed: 3.3ms preprocess, 321.3ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 245.0ms\n",
            "Speed: 3.3ms preprocess, 245.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 203.4ms\n",
            "Speed: 3.1ms preprocess, 203.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 202.8ms\n",
            "Speed: 3.2ms preprocess, 202.8ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 205.1ms\n",
            "Speed: 3.7ms preprocess, 205.1ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 199.0ms\n",
            "Speed: 3.2ms preprocess, 199.0ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 189.1ms\n",
            "Speed: 3.1ms preprocess, 189.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 199.9ms\n",
            "Speed: 3.1ms preprocess, 199.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 196.8ms\n",
            "Speed: 3.5ms preprocess, 196.8ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 199.4ms\n",
            "Speed: 3.3ms preprocess, 199.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 195.3ms\n",
            "Speed: 3.3ms preprocess, 195.3ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 201.4ms\n",
            "Speed: 3.2ms preprocess, 201.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 dog, 218.2ms\n",
            "Speed: 3.4ms preprocess, 218.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 204.6ms\n",
            "Speed: 4.7ms preprocess, 204.6ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 dog, 202.5ms\n",
            "Speed: 3.2ms preprocess, 202.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 213.1ms\n",
            "Speed: 3.4ms preprocess, 213.1ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 207.7ms\n",
            "Speed: 3.5ms preprocess, 207.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 dog, 203.4ms\n",
            "Speed: 3.3ms preprocess, 203.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 202.8ms\n",
            "Speed: 7.7ms preprocess, 202.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 201.7ms\n",
            "Speed: 3.4ms preprocess, 201.7ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 205.1ms\n",
            "Speed: 3.5ms preprocess, 205.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 215.2ms\n",
            "Speed: 3.8ms preprocess, 215.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 196.5ms\n",
            "Speed: 3.5ms preprocess, 196.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 208.5ms\n",
            "Speed: 8.3ms preprocess, 208.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 198.9ms\n",
            "Speed: 3.6ms preprocess, 198.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 195.9ms\n",
            "Speed: 3.5ms preprocess, 195.9ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 212.6ms\n",
            "Speed: 3.4ms preprocess, 212.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 dog, 201.4ms\n",
            "Speed: 2.6ms preprocess, 201.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 dog, 202.9ms\n",
            "Speed: 3.4ms preprocess, 202.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 205.1ms\n",
            "Speed: 3.3ms preprocess, 205.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 214.8ms\n",
            "Speed: 3.3ms preprocess, 214.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 208.7ms\n",
            "Speed: 3.3ms preprocess, 208.7ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 203.1ms\n",
            "Speed: 3.3ms preprocess, 203.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 dog, 190.5ms\n",
            "Speed: 7.3ms preprocess, 190.5ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 197.8ms\n",
            "Speed: 3.2ms preprocess, 197.8ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 208.3ms\n",
            "Speed: 3.4ms preprocess, 208.3ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 199.5ms\n",
            "Speed: 5.4ms preprocess, 199.5ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 194.4ms\n",
            "Speed: 3.3ms preprocess, 194.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 200.7ms\n",
            "Speed: 5.1ms preprocess, 200.7ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 196.8ms\n",
            "Speed: 3.8ms preprocess, 196.8ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 218.2ms\n",
            "Speed: 3.0ms preprocess, 218.2ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 213.5ms\n",
            "Speed: 4.4ms preprocess, 213.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 209.5ms\n",
            "Speed: 3.3ms preprocess, 209.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 205.0ms\n",
            "Speed: 3.6ms preprocess, 205.0ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 216.3ms\n",
            "Speed: 4.8ms preprocess, 216.3ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 208.8ms\n",
            "Speed: 3.7ms preprocess, 208.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 247.9ms\n",
            "Speed: 3.3ms preprocess, 247.9ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 322.9ms\n",
            "Speed: 3.4ms preprocess, 322.9ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 332.4ms\n",
            "Speed: 3.3ms preprocess, 332.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 339.4ms\n",
            "Speed: 3.4ms preprocess, 339.4ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 311.9ms\n",
            "Speed: 4.2ms preprocess, 311.9ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 326.8ms\n",
            "Speed: 3.7ms preprocess, 326.8ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 326.8ms\n",
            "Speed: 3.9ms preprocess, 326.8ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 317.3ms\n",
            "Speed: 3.1ms preprocess, 317.3ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 316.4ms\n",
            "Speed: 4.5ms preprocess, 316.4ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 312.9ms\n",
            "Speed: 4.3ms preprocess, 312.9ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 200.7ms\n",
            "Speed: 3.4ms preprocess, 200.7ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 208.1ms\n",
            "Speed: 3.6ms preprocess, 208.1ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 212.1ms\n",
            "Speed: 3.4ms preprocess, 212.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 199.1ms\n",
            "Speed: 3.6ms preprocess, 199.1ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 208.1ms\n",
            "Speed: 3.2ms preprocess, 208.1ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 208.0ms\n",
            "Speed: 3.1ms preprocess, 208.0ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 200.5ms\n",
            "Speed: 3.3ms preprocess, 200.5ms inference, 3.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 1 handbag, 215.2ms\n",
            "Speed: 7.5ms preprocess, 215.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bench, 197.9ms\n",
            "Speed: 5.2ms preprocess, 197.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 195.7ms\n",
            "Speed: 3.9ms preprocess, 195.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 212.2ms\n",
            "Speed: 5.0ms preprocess, 212.2ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 210.8ms\n",
            "Speed: 3.3ms preprocess, 210.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 206.2ms\n",
            "Speed: 3.4ms preprocess, 206.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 201.8ms\n",
            "Speed: 3.8ms preprocess, 201.8ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 206.6ms\n",
            "Speed: 3.6ms preprocess, 206.6ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 203.9ms\n",
            "Speed: 3.9ms preprocess, 203.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 bird, 222.8ms\n",
            "Speed: 3.3ms preprocess, 222.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 197.2ms\n",
            "Speed: 3.5ms preprocess, 197.2ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 195.6ms\n",
            "Speed: 5.9ms preprocess, 195.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 bird, 201.9ms\n",
            "Speed: 3.4ms preprocess, 201.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 222.1ms\n",
            "Speed: 3.5ms preprocess, 222.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 197.4ms\n",
            "Speed: 4.2ms preprocess, 197.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 202.8ms\n",
            "Speed: 5.3ms preprocess, 202.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 212.0ms\n",
            "Speed: 4.0ms preprocess, 212.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 207.5ms\n",
            "Speed: 4.0ms preprocess, 207.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 214.1ms\n",
            "Speed: 4.2ms preprocess, 214.1ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 192.1ms\n",
            "Speed: 4.1ms preprocess, 192.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 192.5ms\n",
            "Speed: 3.8ms preprocess, 192.5ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 193.9ms\n",
            "Speed: 3.2ms preprocess, 193.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 192.7ms\n",
            "Speed: 5.1ms preprocess, 192.7ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 207.1ms\n",
            "Speed: 4.0ms preprocess, 207.1ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 192.9ms\n",
            "Speed: 3.7ms preprocess, 192.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 199.8ms\n",
            "Speed: 4.4ms preprocess, 199.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 207.3ms\n",
            "Speed: 4.0ms preprocess, 207.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 206.7ms\n",
            "Speed: 3.2ms preprocess, 206.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 208.2ms\n",
            "Speed: 3.6ms preprocess, 208.2ms inference, 3.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 200.3ms\n",
            "Speed: 3.7ms preprocess, 200.3ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 202.0ms\n",
            "Speed: 3.4ms preprocess, 202.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 202.2ms\n",
            "Speed: 4.1ms preprocess, 202.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 211.9ms\n",
            "Speed: 3.4ms preprocess, 211.9ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 207.9ms\n",
            "Speed: 3.5ms preprocess, 207.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 203.5ms\n",
            "Speed: 3.2ms preprocess, 203.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 207.1ms\n",
            "Speed: 3.3ms preprocess, 207.1ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 211.8ms\n",
            "Speed: 3.3ms preprocess, 211.8ms inference, 2.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 194.5ms\n",
            "Speed: 3.4ms preprocess, 194.5ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 284.2ms\n",
            "Speed: 3.1ms preprocess, 284.2ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 322.9ms\n",
            "Speed: 3.2ms preprocess, 322.9ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 335.8ms\n",
            "Speed: 3.3ms preprocess, 335.8ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 324.0ms\n",
            "Speed: 3.3ms preprocess, 324.0ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 313.8ms\n",
            "Speed: 3.2ms preprocess, 313.8ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 330.5ms\n",
            "Speed: 3.4ms preprocess, 330.5ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 316.8ms\n",
            "Speed: 3.2ms preprocess, 316.8ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 345.8ms\n",
            "Speed: 3.3ms preprocess, 345.8ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 318.5ms\n",
            "Speed: 3.2ms preprocess, 318.5ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 273.2ms\n",
            "Speed: 3.3ms preprocess, 273.2ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 207.6ms\n",
            "Speed: 3.8ms preprocess, 207.6ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 220.3ms\n",
            "Speed: 4.2ms preprocess, 220.3ms inference, 0.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 210.9ms\n",
            "Speed: 3.3ms preprocess, 210.9ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 201.2ms\n",
            "Speed: 3.5ms preprocess, 201.2ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 dog, 211.2ms\n",
            "Speed: 3.5ms preprocess, 211.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 209.7ms\n",
            "Speed: 3.9ms preprocess, 209.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 205.6ms\n",
            "Speed: 3.4ms preprocess, 205.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 221.3ms\n",
            "Speed: 3.8ms preprocess, 221.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 214.8ms\n",
            "Speed: 3.6ms preprocess, 214.8ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 204.3ms\n",
            "Speed: 4.2ms preprocess, 204.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 208.3ms\n",
            "Speed: 3.6ms preprocess, 208.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 203.8ms\n",
            "Speed: 5.6ms preprocess, 203.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 199.9ms\n",
            "Speed: 3.2ms preprocess, 199.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 207.7ms\n",
            "Speed: 3.3ms preprocess, 207.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 202.0ms\n",
            "Speed: 3.3ms preprocess, 202.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 197.5ms\n",
            "Speed: 3.2ms preprocess, 197.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 208.4ms\n",
            "Speed: 3.3ms preprocess, 208.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 193.9ms\n",
            "Speed: 3.3ms preprocess, 193.9ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 198.6ms\n",
            "Speed: 6.3ms preprocess, 198.6ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 205.0ms\n",
            "Speed: 4.4ms preprocess, 205.0ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 210.3ms\n",
            "Speed: 3.3ms preprocess, 210.3ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 211.6ms\n",
            "Speed: 3.6ms preprocess, 211.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 198.9ms\n",
            "Speed: 6.7ms preprocess, 198.9ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 215.4ms\n",
            "Speed: 3.7ms preprocess, 215.4ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 202.9ms\n",
            "Speed: 4.0ms preprocess, 202.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 213.7ms\n",
            "Speed: 4.2ms preprocess, 213.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 203.5ms\n",
            "Speed: 3.8ms preprocess, 203.5ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 198.7ms\n",
            "Speed: 3.3ms preprocess, 198.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 208.3ms\n",
            "Speed: 6.0ms preprocess, 208.3ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 199.7ms\n",
            "Speed: 3.8ms preprocess, 199.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 216.5ms\n",
            "Speed: 4.0ms preprocess, 216.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 202.8ms\n",
            "Speed: 5.6ms preprocess, 202.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 208.5ms\n",
            "Speed: 3.3ms preprocess, 208.5ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 210.1ms\n",
            "Speed: 3.4ms preprocess, 210.1ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 214.3ms\n",
            "Speed: 3.2ms preprocess, 214.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 205.9ms\n",
            "Speed: 3.9ms preprocess, 205.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 206.2ms\n",
            "Speed: 3.8ms preprocess, 206.2ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 211.3ms\n",
            "Speed: 4.2ms preprocess, 211.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 201.4ms\n",
            "Speed: 3.3ms preprocess, 201.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 205.9ms\n",
            "Speed: 3.7ms preprocess, 205.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 213.5ms\n",
            "Speed: 3.2ms preprocess, 213.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 206.7ms\n",
            "Speed: 4.4ms preprocess, 206.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 handbag, 241.9ms\n",
            "Speed: 3.3ms preprocess, 241.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 207.4ms\n",
            "Speed: 3.3ms preprocess, 207.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 bench, 321.8ms\n",
            "Speed: 3.4ms preprocess, 321.8ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 2 benchs, 326.9ms\n",
            "Speed: 3.7ms preprocess, 326.9ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 bench, 331.1ms\n",
            "Speed: 3.6ms preprocess, 331.1ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 bench, 314.4ms\n",
            "Speed: 3.4ms preprocess, 314.4ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 347.3ms\n",
            "Speed: 3.4ms preprocess, 347.3ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 326.8ms\n",
            "Speed: 3.4ms preprocess, 326.8ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 352.8ms\n",
            "Speed: 3.3ms preprocess, 352.8ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 310.1ms\n",
            "Speed: 3.3ms preprocess, 310.1ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 326.4ms\n",
            "Speed: 3.6ms preprocess, 326.4ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 handbag, 297.7ms\n",
            "Speed: 3.4ms preprocess, 297.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 206.5ms\n",
            "Speed: 3.7ms preprocess, 206.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 truck, 209.9ms\n",
            "Speed: 3.7ms preprocess, 209.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 230.4ms\n",
            "Speed: 3.6ms preprocess, 230.4ms inference, 2.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 204.3ms\n",
            "Speed: 3.5ms preprocess, 204.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 216.0ms\n",
            "Speed: 3.3ms preprocess, 216.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 202.7ms\n",
            "Speed: 3.4ms preprocess, 202.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 204.5ms\n",
            "Speed: 4.0ms preprocess, 204.5ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 215.3ms\n",
            "Speed: 5.4ms preprocess, 215.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 204.9ms\n",
            "Speed: 3.4ms preprocess, 204.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 195.7ms\n",
            "Speed: 5.9ms preprocess, 195.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 200.6ms\n",
            "Speed: 4.6ms preprocess, 200.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 212.1ms\n",
            "Speed: 4.5ms preprocess, 212.1ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 208.3ms\n",
            "Speed: 3.7ms preprocess, 208.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 199.9ms\n",
            "Speed: 3.4ms preprocess, 199.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 197.8ms\n",
            "Speed: 3.3ms preprocess, 197.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 209.4ms\n",
            "Speed: 7.1ms preprocess, 209.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 208.2ms\n",
            "Speed: 4.4ms preprocess, 208.2ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 217.8ms\n",
            "Speed: 3.9ms preprocess, 217.8ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 210.6ms\n",
            "Speed: 3.9ms preprocess, 210.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 206.4ms\n",
            "Speed: 7.4ms preprocess, 206.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 206.8ms\n",
            "Speed: 4.4ms preprocess, 206.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 215.4ms\n",
            "Speed: 3.5ms preprocess, 215.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 1 tie, 201.7ms\n",
            "Speed: 3.4ms preprocess, 201.7ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 1 car, 1 tie, 202.6ms\n",
            "Speed: 3.6ms preprocess, 202.6ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 tie, 208.9ms\n",
            "Speed: 3.5ms preprocess, 208.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 1 car, 1 tie, 224.4ms\n",
            "Speed: 3.7ms preprocess, 224.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 204.5ms\n",
            "Speed: 3.7ms preprocess, 204.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 1 car, 1 tie, 205.6ms\n",
            "Speed: 3.6ms preprocess, 205.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 2 ties, 200.9ms\n",
            "Speed: 3.2ms preprocess, 200.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 handbag, 1 tie, 200.2ms\n",
            "Speed: 3.4ms preprocess, 200.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 1 car, 1 tie, 214.5ms\n",
            "Speed: 4.4ms preprocess, 214.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 1 tie, 212.4ms\n",
            "Speed: 3.2ms preprocess, 212.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 handbag, 1 tie, 208.3ms\n",
            "Speed: 3.2ms preprocess, 208.3ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 1 car, 1 tie, 203.0ms\n",
            "Speed: 4.0ms preprocess, 203.0ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 1 tie, 214.4ms\n",
            "Speed: 3.9ms preprocess, 214.4ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 1 tie, 200.4ms\n",
            "Speed: 7.1ms preprocess, 200.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 1 car, 1 tie, 204.9ms\n",
            "Speed: 4.0ms preprocess, 204.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 215.1ms\n",
            "Speed: 3.9ms preprocess, 215.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 215.5ms\n",
            "Speed: 4.3ms preprocess, 215.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 218.6ms\n",
            "Speed: 3.1ms preprocess, 218.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 1 car, 205.6ms\n",
            "Speed: 4.8ms preprocess, 205.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 1 tie, 204.9ms\n",
            "Speed: 3.9ms preprocess, 204.9ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 1 tie, 209.0ms\n",
            "Speed: 3.3ms preprocess, 209.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 tie, 231.7ms\n",
            "Speed: 4.4ms preprocess, 231.7ms inference, 3.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 1 car, 1 tie, 323.3ms\n",
            "Speed: 4.0ms preprocess, 323.3ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 1 tie, 330.0ms\n",
            "Speed: 3.4ms preprocess, 330.0ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 1 tie, 351.7ms\n",
            "Speed: 3.3ms preprocess, 351.7ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 1 tie, 342.4ms\n",
            "Speed: 3.3ms preprocess, 342.4ms inference, 2.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 1 tie, 323.8ms\n",
            "Speed: 4.4ms preprocess, 323.8ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 tie, 341.2ms\n",
            "Speed: 3.7ms preprocess, 341.2ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 1 tie, 334.0ms\n",
            "Speed: 3.3ms preprocess, 334.0ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 1 tie, 330.3ms\n",
            "Speed: 3.5ms preprocess, 330.3ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 1 car, 1 tie, 320.3ms\n",
            "Speed: 3.2ms preprocess, 320.3ms inference, 2.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 5 persons, 1 car, 2 ties, 256.2ms\n",
            "Speed: 3.8ms preprocess, 256.2ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 1 tie, 204.7ms\n",
            "Speed: 3.8ms preprocess, 204.7ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 tie, 204.0ms\n",
            "Speed: 3.7ms preprocess, 204.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 1 car, 1 tie, 220.6ms\n",
            "Speed: 3.5ms preprocess, 220.6ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 1 tie, 202.5ms\n",
            "Speed: 3.3ms preprocess, 202.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 1 handbag, 1 tie, 207.3ms\n",
            "Speed: 3.7ms preprocess, 207.3ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 204.5ms\n",
            "Speed: 3.6ms preprocess, 204.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 203.4ms\n",
            "Speed: 3.5ms preprocess, 203.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 208.1ms\n",
            "Speed: 4.2ms preprocess, 208.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 203.5ms\n",
            "Speed: 3.7ms preprocess, 203.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 211.2ms\n",
            "Speed: 3.7ms preprocess, 211.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 211.0ms\n",
            "Speed: 3.8ms preprocess, 211.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 handbag, 1 tie, 200.9ms\n",
            "Speed: 3.6ms preprocess, 200.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 205.2ms\n",
            "Speed: 3.3ms preprocess, 205.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 1 tie, 212.1ms\n",
            "Speed: 4.8ms preprocess, 212.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 1 tie, 223.9ms\n",
            "Speed: 4.3ms preprocess, 223.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 2 ties, 215.3ms\n",
            "Speed: 6.1ms preprocess, 215.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 215.1ms\n",
            "Speed: 3.4ms preprocess, 215.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 208.6ms\n",
            "Speed: 3.2ms preprocess, 208.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 bench, 1 tie, 214.2ms\n",
            "Speed: 3.3ms preprocess, 214.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 275.8ms\n",
            "Speed: 3.4ms preprocess, 275.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 1 tie, 211.3ms\n",
            "Speed: 3.4ms preprocess, 211.3ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 4 persons, 1 tie, 213.4ms\n",
            "Speed: 3.5ms preprocess, 213.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 228.0ms\n",
            "Speed: 3.4ms preprocess, 228.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 207.8ms\n",
            "Speed: 4.2ms preprocess, 207.8ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 218.7ms\n",
            "Speed: 3.6ms preprocess, 218.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 213.2ms\n",
            "Speed: 3.5ms preprocess, 213.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 handbag, 1 tie, 210.3ms\n",
            "Speed: 3.4ms preprocess, 210.3ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 handbag, 1 tie, 219.0ms\n",
            "Speed: 3.7ms preprocess, 219.0ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 212.4ms\n",
            "Speed: 3.4ms preprocess, 212.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 215.2ms\n",
            "Speed: 4.0ms preprocess, 215.2ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 210.1ms\n",
            "Speed: 4.1ms preprocess, 210.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 215.7ms\n",
            "Speed: 3.5ms preprocess, 215.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 handbag, 1 tie, 217.7ms\n",
            "Speed: 3.4ms preprocess, 217.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 207.1ms\n",
            "Speed: 3.2ms preprocess, 207.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 2 handbags, 1 tie, 221.8ms\n",
            "Speed: 3.3ms preprocess, 221.8ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 219.9ms\n",
            "Speed: 3.9ms preprocess, 219.9ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 1 tie, 210.6ms\n",
            "Speed: 4.0ms preprocess, 210.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 217.2ms\n",
            "Speed: 3.3ms preprocess, 217.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 handbag, 1 tie, 211.1ms\n",
            "Speed: 4.1ms preprocess, 211.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 2 handbags, 1 tie, 206.7ms\n",
            "Speed: 3.2ms preprocess, 206.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 203.0ms\n",
            "Speed: 3.5ms preprocess, 203.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 212.1ms\n",
            "Speed: 3.6ms preprocess, 212.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 229.0ms\n",
            "Speed: 3.9ms preprocess, 229.0ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 handbag, 325.3ms\n",
            "Speed: 5.8ms preprocess, 325.3ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 325.1ms\n",
            "Speed: 3.2ms preprocess, 325.1ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 2 ties, 320.2ms\n",
            "Speed: 4.4ms preprocess, 320.2ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 329.5ms\n",
            "Speed: 6.4ms preprocess, 329.5ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 319.7ms\n",
            "Speed: 3.6ms preprocess, 319.7ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 handbag, 2 ties, 324.2ms\n",
            "Speed: 3.3ms preprocess, 324.2ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 325.0ms\n",
            "Speed: 3.4ms preprocess, 325.0ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 332.5ms\n",
            "Speed: 3.7ms preprocess, 332.5ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 315.9ms\n",
            "Speed: 3.3ms preprocess, 315.9ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 276.4ms\n",
            "Speed: 3.9ms preprocess, 276.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 1 tie, 199.9ms\n",
            "Speed: 3.2ms preprocess, 199.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 214.6ms\n",
            "Speed: 4.1ms preprocess, 214.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 tie, 196.4ms\n",
            "Speed: 3.3ms preprocess, 196.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 1 tie, 216.2ms\n",
            "Speed: 6.4ms preprocess, 216.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 204.9ms\n",
            "Speed: 3.6ms preprocess, 204.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 1 car, 1 tie, 195.5ms\n",
            "Speed: 4.3ms preprocess, 195.5ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 cars, 1 tie, 193.8ms\n",
            "Speed: 3.8ms preprocess, 193.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 219.2ms\n",
            "Speed: 3.1ms preprocess, 219.2ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 218.7ms\n",
            "Speed: 4.4ms preprocess, 218.7ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 tie, 208.3ms\n",
            "Speed: 3.4ms preprocess, 208.3ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 217.4ms\n",
            "Speed: 3.4ms preprocess, 217.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 202.7ms\n",
            "Speed: 3.4ms preprocess, 202.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 tie, 214.9ms\n",
            "Speed: 3.4ms preprocess, 214.9ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 1 tie, 216.3ms\n",
            "Speed: 3.6ms preprocess, 216.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 205.3ms\n",
            "Speed: 4.0ms preprocess, 205.3ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 1 tie, 212.7ms\n",
            "Speed: 3.8ms preprocess, 212.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 1 tie, 215.9ms\n",
            "Speed: 3.4ms preprocess, 215.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 223.0ms\n",
            "Speed: 4.0ms preprocess, 223.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 204.5ms\n",
            "Speed: 8.5ms preprocess, 204.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 205.3ms\n",
            "Speed: 4.0ms preprocess, 205.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 204.6ms\n",
            "Speed: 3.7ms preprocess, 204.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 214.1ms\n",
            "Speed: 3.8ms preprocess, 214.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 204.1ms\n",
            "Speed: 3.3ms preprocess, 204.1ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 215.0ms\n",
            "Speed: 6.0ms preprocess, 215.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 handbag, 1 tie, 211.0ms\n",
            "Speed: 4.0ms preprocess, 211.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 212.9ms\n",
            "Speed: 4.1ms preprocess, 212.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 229.0ms\n",
            "Speed: 3.7ms preprocess, 229.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 203.8ms\n",
            "Speed: 3.8ms preprocess, 203.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 210.6ms\n",
            "Speed: 3.6ms preprocess, 210.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 213.3ms\n",
            "Speed: 3.3ms preprocess, 213.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 2 ties, 223.0ms\n",
            "Speed: 3.1ms preprocess, 223.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 2 ties, 199.5ms\n",
            "Speed: 3.2ms preprocess, 199.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 210.1ms\n",
            "Speed: 3.6ms preprocess, 210.1ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 tie, 196.1ms\n",
            "Speed: 4.0ms preprocess, 196.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 tie, 201.8ms\n",
            "Speed: 3.5ms preprocess, 201.8ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 car, 1 tie, 203.3ms\n",
            "Speed: 3.7ms preprocess, 203.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 car, 207.8ms\n",
            "Speed: 4.5ms preprocess, 207.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 198.1ms\n",
            "Speed: 3.6ms preprocess, 198.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 201.5ms\n",
            "Speed: 3.2ms preprocess, 201.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 203.4ms\n",
            "Speed: 3.4ms preprocess, 203.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 214.1ms\n",
            "Speed: 3.5ms preprocess, 214.1ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 205.6ms\n",
            "Speed: 3.3ms preprocess, 205.6ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 206.8ms\n",
            "Speed: 3.3ms preprocess, 206.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 245.4ms\n",
            "Speed: 3.4ms preprocess, 245.4ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 324.1ms\n",
            "Speed: 3.4ms preprocess, 324.1ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 334.1ms\n",
            "Speed: 3.5ms preprocess, 334.1ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 329.8ms\n",
            "Speed: 3.4ms preprocess, 329.8ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 334.0ms\n",
            "Speed: 3.2ms preprocess, 334.0ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 stop sign, 319.4ms\n",
            "Speed: 3.5ms preprocess, 319.4ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 324.3ms\n",
            "Speed: 4.1ms preprocess, 324.3ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 334.3ms\n",
            "Speed: 3.3ms preprocess, 334.3ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 326.1ms\n",
            "Speed: 3.3ms preprocess, 326.1ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 331.3ms\n",
            "Speed: 3.3ms preprocess, 331.3ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 269.4ms\n",
            "Speed: 3.9ms preprocess, 269.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 217.2ms\n",
            "Speed: 3.5ms preprocess, 217.2ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 dog, 205.5ms\n",
            "Speed: 4.4ms preprocess, 205.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 209.5ms\n",
            "Speed: 5.0ms preprocess, 209.5ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 dog, 207.7ms\n",
            "Speed: 4.5ms preprocess, 207.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 202.2ms\n",
            "Speed: 3.8ms preprocess, 202.2ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 dog, 1 handbag, 198.3ms\n",
            "Speed: 3.5ms preprocess, 198.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 dog, 208.7ms\n",
            "Speed: 3.3ms preprocess, 208.7ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 200.2ms\n",
            "Speed: 3.2ms preprocess, 200.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 210.5ms\n",
            "Speed: 3.5ms preprocess, 210.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 196.8ms\n",
            "Speed: 3.3ms preprocess, 196.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 210.0ms\n",
            "Speed: 4.1ms preprocess, 210.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 215.0ms\n",
            "Speed: 3.1ms preprocess, 215.0ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 206.2ms\n",
            "Speed: 3.6ms preprocess, 206.2ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 213.3ms\n",
            "Speed: 3.2ms preprocess, 213.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 200.5ms\n",
            "Speed: 3.8ms preprocess, 200.5ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 208.9ms\n",
            "Speed: 3.6ms preprocess, 208.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 199.1ms\n",
            "Speed: 6.0ms preprocess, 199.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 218.8ms\n",
            "Speed: 3.2ms preprocess, 218.8ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 200.6ms\n",
            "Speed: 4.2ms preprocess, 200.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 203.9ms\n",
            "Speed: 4.1ms preprocess, 203.9ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 204.7ms\n",
            "Speed: 4.1ms preprocess, 204.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 216.1ms\n",
            "Speed: 3.5ms preprocess, 216.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 212.4ms\n",
            "Speed: 3.2ms preprocess, 212.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 201.9ms\n",
            "Speed: 3.3ms preprocess, 201.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 205.1ms\n",
            "Speed: 5.3ms preprocess, 205.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 207.8ms\n",
            "Speed: 3.2ms preprocess, 207.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 207.5ms\n",
            "Speed: 3.2ms preprocess, 207.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 194.6ms\n",
            "Speed: 3.6ms preprocess, 194.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 204.3ms\n",
            "Speed: 3.1ms preprocess, 204.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 191.9ms\n",
            "Speed: 3.4ms preprocess, 191.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 206.5ms\n",
            "Speed: 3.3ms preprocess, 206.5ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 208.8ms\n",
            "Speed: 4.2ms preprocess, 208.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 1 dog, 208.9ms\n",
            "Speed: 3.1ms preprocess, 208.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 204.6ms\n",
            "Speed: 8.8ms preprocess, 204.6ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 211.3ms\n",
            "Speed: 3.5ms preprocess, 211.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 208.2ms\n",
            "Speed: 6.7ms preprocess, 208.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 221.2ms\n",
            "Speed: 3.7ms preprocess, 221.2ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 215.9ms\n",
            "Speed: 3.3ms preprocess, 215.9ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 214.1ms\n",
            "Speed: 3.6ms preprocess, 214.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 215.4ms\n",
            "Speed: 3.6ms preprocess, 215.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 213.5ms\n",
            "Speed: 3.2ms preprocess, 213.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 208.9ms\n",
            "Speed: 3.4ms preprocess, 208.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 207.7ms\n",
            "Speed: 5.3ms preprocess, 207.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 229.0ms\n",
            "Speed: 5.2ms preprocess, 229.0ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 359.4ms\n",
            "Speed: 5.6ms preprocess, 359.4ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 333.4ms\n",
            "Speed: 3.3ms preprocess, 333.4ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 343.5ms\n",
            "Speed: 6.3ms preprocess, 343.5ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 316.2ms\n",
            "Speed: 3.2ms preprocess, 316.2ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 315.1ms\n",
            "Speed: 3.2ms preprocess, 315.1ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 319.2ms\n",
            "Speed: 8.6ms preprocess, 319.2ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 326.4ms\n",
            "Speed: 3.2ms preprocess, 326.4ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 322.7ms\n",
            "Speed: 3.2ms preprocess, 322.7ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 299.9ms\n",
            "Speed: 3.8ms preprocess, 299.9ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 242.1ms\n",
            "Speed: 3.2ms preprocess, 242.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 239.9ms\n",
            "Speed: 3.7ms preprocess, 239.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 dog, 206.5ms\n",
            "Speed: 3.1ms preprocess, 206.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 206.6ms\n",
            "Speed: 3.9ms preprocess, 206.6ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 197.8ms\n",
            "Speed: 4.1ms preprocess, 197.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 212.3ms\n",
            "Speed: 3.9ms preprocess, 212.3ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 1 dog, 200.3ms\n",
            "Speed: 3.4ms preprocess, 200.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 211.0ms\n",
            "Speed: 3.3ms preprocess, 211.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 206.9ms\n",
            "Speed: 3.5ms preprocess, 206.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 198.5ms\n",
            "Speed: 3.5ms preprocess, 198.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 217.2ms\n",
            "Speed: 3.3ms preprocess, 217.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 210.5ms\n",
            "Speed: 3.4ms preprocess, 210.5ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 bench, 207.4ms\n",
            "Speed: 3.6ms preprocess, 207.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 198.7ms\n",
            "Speed: 3.5ms preprocess, 198.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 228.5ms\n",
            "Speed: 3.2ms preprocess, 228.5ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 206.6ms\n",
            "Speed: 3.6ms preprocess, 206.6ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 1 dog, 210.4ms\n",
            "Speed: 3.4ms preprocess, 210.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 201.3ms\n",
            "Speed: 3.3ms preprocess, 201.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 207.5ms\n",
            "Speed: 4.7ms preprocess, 207.5ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 207.1ms\n",
            "Speed: 3.4ms preprocess, 207.1ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 198.8ms\n",
            "Speed: 3.5ms preprocess, 198.8ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 196.4ms\n",
            "Speed: 3.3ms preprocess, 196.4ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 197.9ms\n",
            "Speed: 3.2ms preprocess, 197.9ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 191.4ms\n",
            "Speed: 3.3ms preprocess, 191.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 205.5ms\n",
            "Speed: 3.0ms preprocess, 205.5ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 192.4ms\n",
            "Speed: 5.5ms preprocess, 192.4ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 191.9ms\n",
            "Speed: 6.4ms preprocess, 191.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 200.3ms\n",
            "Speed: 3.1ms preprocess, 200.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 215.9ms\n",
            "Speed: 6.8ms preprocess, 215.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 205.0ms\n",
            "Speed: 3.6ms preprocess, 205.0ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 208.0ms\n",
            "Speed: 3.8ms preprocess, 208.0ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 204.8ms\n",
            "Speed: 3.3ms preprocess, 204.8ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 208.5ms\n",
            "Speed: 3.3ms preprocess, 208.5ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 216.8ms\n",
            "Speed: 3.5ms preprocess, 216.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 206.6ms\n",
            "Speed: 3.3ms preprocess, 206.6ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 210.6ms\n",
            "Speed: 3.3ms preprocess, 210.6ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 201.4ms\n",
            "Speed: 3.3ms preprocess, 201.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 202.8ms\n",
            "Speed: 3.4ms preprocess, 202.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 (no detections), 219.8ms\n",
            "Speed: 5.3ms preprocess, 219.8ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 201.3ms\n",
            "Speed: 4.3ms preprocess, 201.3ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 211.4ms\n",
            "Speed: 3.7ms preprocess, 211.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 213.1ms\n",
            "Speed: 3.4ms preprocess, 213.1ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 219.2ms\n",
            "Speed: 3.9ms preprocess, 219.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 206.3ms\n",
            "Speed: 3.8ms preprocess, 206.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 203.9ms\n",
            "Speed: 3.1ms preprocess, 203.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 313.1ms\n",
            "Speed: 3.3ms preprocess, 313.1ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 327.9ms\n",
            "Speed: 4.8ms preprocess, 327.9ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 312.8ms\n",
            "Speed: 3.3ms preprocess, 312.8ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 305.4ms\n",
            "Speed: 3.1ms preprocess, 305.4ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 3 persons, 308.4ms\n",
            "Speed: 3.7ms preprocess, 308.4ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 309.0ms\n",
            "Speed: 3.2ms preprocess, 309.0ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 311.5ms\n",
            "Speed: 3.2ms preprocess, 311.5ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 322.7ms\n",
            "Speed: 3.4ms preprocess, 322.7ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 341.8ms\n",
            "Speed: 3.6ms preprocess, 341.8ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 320.2ms\n",
            "Speed: 3.3ms preprocess, 320.2ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 244.6ms\n",
            "Speed: 4.4ms preprocess, 244.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "video_path = \"/content/Terror Detection_Guns.3gp\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "\n",
        "size = (frame_width, frame_height)\n",
        "\n",
        "# Below VideoWriter object will create\n",
        "# a frame of above defined The output\n",
        "# is stored in 'filename.avi' file.\n",
        "result = cv2.VideoWriter('filename.avi',\n",
        "                         cv2.VideoWriter_fourcc(*'MJPG'),\n",
        "                         20, size)\n",
        "while cap.isOpened():\n",
        "    # Read a frame from the video\n",
        "    success, frame = cap.read()\n",
        "\n",
        "    if success:\n",
        "        # Run YOLOv8 inference on the frame\n",
        "        results = model(frame)\n",
        "\n",
        "        # Visualize the results on the frame\n",
        "        annotated_frame = results[0].plot()\n",
        "        result.write(annotated_frame)\n",
        "\n",
        "        # Display the annotated frame\n",
        "        #cv2.imshow(\"Weapon Detection\", annotated_frame)\n",
        "\n",
        "\n",
        "        # Break the loop if 'q' is pressed\n",
        "        if cv2.waitKey(3) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "    else:\n",
        "        # Break the loop if the end of the video is reached\n",
        "        break\n",
        "\n",
        "# Release the video capture object and close the display window\n",
        "cap.release()\n",
        "result.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "id": "8e0a4ef0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "107f4380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b86eb3a-8c9c-4dcf-f43b-1126ea5057c8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=84x1>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAABCAIAAADPSh7SAAAAyklEQVR4nAXBIUsDcRzG8S++goFvYGA0bLPP5/e8APGKDB3ChduQw3AI/tPCxSuCcSCDC4LG2dwsKwaLWbEMg6/AKvj5AAAdp90LAQGV10cTQQTc+n3vUFAHtPH3PRG0AV2fTKeCTcAmxqsk2AZAMZgJMES87F8LOobMr18SdA3bGN2Vgr6BuPlJgjDM3RseCzIDLheFIDc0fngqBZWh753fJGgMH35rzgVzQ63xZSVoDeF0dSp4NNQuDs4ES0Pu+0UueDYsnX0O9Q/1dj3LE/08OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load your custom YOLOv5 model from a local .pt file\n",
        "custom_model_path = '/content/runs/detect/train/weights/best.pt'  # Replace with the path to your custom .pt model file\n",
        "checkpoint = torch.load(custom_model_path, map_location=torch.device('cpu'))\n",
        "model = checkpoint['model'].float()  # Access the YOLOv5 model from the dictionary\n",
        "model.eval()\n",
        "\n",
        "# Expected input size of your custom YOLOv5 model (replace with your model's input size)\n",
        "model_input_size = (640, 640)  # Example: (width, height)\n",
        "\n",
        "# Open the video file\n",
        "video_path = 'Terror Detection_Guns.3gp'  # Replace with the path to your video file\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "size = (frame_width, frame_height)\n",
        "\n",
        "# Create a VideoWriter object to save the annotated video\n",
        "output_path = 'filename.avi'\n",
        "result = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'MJPG'), 20, size)\n",
        "\n",
        "while cap.isOpened():\n",
        "    # Read a frame from the video\n",
        "    success, frame = cap.read()\n",
        "\n",
        "    if success:\n",
        "        # Resize the frame to match the model's input size\n",
        "        img = cv2.resize(frame, model_input_size)\n",
        "        img = torch.from_numpy(img).float() / 255.0\n",
        "        img = img.permute(2, 0, 1).unsqueeze(0)\n",
        "\n",
        "        # Run your custom YOLOv5 model inference on the frame\n",
        "        with torch.no_grad():\n",
        "            results = model(img)\n",
        "\n",
        "        # Modify this part based on the structure of your results tuple\n",
        "        annotated_frame = results[0]  # Access the annotated frame\n",
        "\n",
        "        # Convert the annotated frame to the appropriate data type (CV_8U)\n",
        "        annotated_frame = (annotated_frame * 255).byte()\n",
        "\n",
        "        # Convert the annotated frame back to OpenCV format\n",
        "        annotated_frame = np.array(annotated_frame)\n",
        "\n",
        "        # Display the annotated frame in Colab using cv2_imshow\n",
        "        cv2_imshow(annotated_frame)\n",
        "\n",
        "        # Write the annotated frame to the output video\n",
        "        result.write(annotated_frame)\n",
        "\n",
        "        # Break the loop if 'q' is pressed\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "    else:\n",
        "        # Break the loop if the end of the video is reached\n",
        "        break\n",
        "\n",
        "# Release the video capture object and release the VideoWriter\n",
        "cap.release()\n",
        "result.release()\n",
        "\n",
        "print(f'Annotated video saved as {output_path}')\n"
      ],
      "id": "107f4380"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}